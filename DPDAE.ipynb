{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserAE - Epoch 1/200, Loss: 20.3226\n",
      "UserAE - Epoch 2/200, Loss: 15.4634\n",
      "UserAE - Epoch 3/200, Loss: 13.9134\n",
      "UserAE - Epoch 4/200, Loss: 13.1813\n",
      "UserAE - Epoch 5/200, Loss: 12.5136\n",
      "UserAE - Epoch 6/200, Loss: 11.9996\n",
      "UserAE - Epoch 7/200, Loss: 11.5649\n",
      "UserAE - Epoch 8/200, Loss: 11.1909\n",
      "UserAE - Epoch 9/200, Loss: 10.8919\n",
      "UserAE - Epoch 10/200, Loss: 10.7064\n",
      "UserAE - Epoch 11/200, Loss: 10.3983\n",
      "UserAE - Epoch 12/200, Loss: 10.2581\n",
      "UserAE - Epoch 13/200, Loss: 10.0612\n",
      "UserAE - Epoch 14/200, Loss: 9.9656\n",
      "UserAE - Epoch 15/200, Loss: 9.8148\n",
      "UserAE - Epoch 16/200, Loss: 9.7063\n",
      "UserAE - Epoch 17/200, Loss: 9.5631\n",
      "UserAE - Epoch 18/200, Loss: 9.5303\n",
      "UserAE - Epoch 19/200, Loss: 9.4352\n",
      "UserAE - Epoch 20/200, Loss: 9.2906\n",
      "UserAE - Epoch 21/200, Loss: 9.2139\n",
      "UserAE - Epoch 22/200, Loss: 9.1827\n",
      "UserAE - Epoch 23/200, Loss: 9.1079\n",
      "UserAE - Epoch 24/200, Loss: 9.1035\n",
      "UserAE - Epoch 25/200, Loss: 8.9831\n",
      "UserAE - Epoch 26/200, Loss: 8.9147\n",
      "UserAE - Epoch 27/200, Loss: 8.9071\n",
      "UserAE - Epoch 28/200, Loss: 8.8291\n",
      "UserAE - Epoch 29/200, Loss: 8.7952\n",
      "UserAE - Epoch 30/200, Loss: 8.7992\n",
      "UserAE - Epoch 31/200, Loss: 8.7944\n",
      "UserAE - Epoch 32/200, Loss: 8.6476\n",
      "UserAE - Epoch 33/200, Loss: 8.5987\n",
      "UserAE - Epoch 34/200, Loss: 8.5875\n",
      "UserAE - Epoch 35/200, Loss: 8.5970\n",
      "UserAE - Epoch 36/200, Loss: 8.6123\n",
      "UserAE - Epoch 37/200, Loss: 8.5631\n",
      "UserAE - Epoch 38/200, Loss: 8.4672\n",
      "UserAE - Epoch 39/200, Loss: 8.5172\n",
      "UserAE - Epoch 40/200, Loss: 8.4783\n",
      "UserAE - Epoch 41/200, Loss: 8.4664\n",
      "UserAE - Epoch 42/200, Loss: 8.4380\n",
      "UserAE - Epoch 43/200, Loss: 8.4267\n",
      "UserAE - Epoch 44/200, Loss: 8.4151\n",
      "UserAE - Epoch 45/200, Loss: 8.4075\n",
      "UserAE - Epoch 46/200, Loss: 8.3750\n",
      "UserAE - Epoch 47/200, Loss: 8.3883\n",
      "UserAE - Epoch 48/200, Loss: 8.3973\n",
      "UserAE - Epoch 49/200, Loss: 8.3388\n",
      "UserAE - Epoch 50/200, Loss: 8.2889\n",
      "UserAE - Epoch 51/200, Loss: 8.2837\n",
      "UserAE - Epoch 52/200, Loss: 8.2811\n",
      "UserAE - Epoch 53/200, Loss: 8.3392\n",
      "UserAE - Epoch 54/200, Loss: 8.3394\n",
      "UserAE - Epoch 55/200, Loss: 8.3144\n",
      "UserAE - Epoch 56/200, Loss: 8.3403\n",
      "UserAE - Epoch 57/200, Loss: 8.2694\n",
      "UserAE - Epoch 58/200, Loss: 8.1971\n",
      "UserAE - Epoch 59/200, Loss: 8.2506\n",
      "UserAE - Epoch 60/200, Loss: 8.2317\n",
      "UserAE - Epoch 61/200, Loss: 8.2178\n",
      "UserAE - Epoch 62/200, Loss: 8.2463\n",
      "UserAE - Epoch 63/200, Loss: 8.2144\n",
      "UserAE - Epoch 64/200, Loss: 8.2015\n",
      "UserAE - Epoch 65/200, Loss: 8.1679\n",
      "UserAE - Epoch 66/200, Loss: 8.2079\n",
      "UserAE - Epoch 67/200, Loss: 8.1592\n",
      "UserAE - Epoch 68/200, Loss: 8.1503\n",
      "UserAE - Epoch 69/200, Loss: 8.1779\n",
      "UserAE - Epoch 70/200, Loss: 8.1648\n",
      "UserAE - Epoch 71/200, Loss: 8.1429\n",
      "UserAE - Epoch 72/200, Loss: 8.1862\n",
      "UserAE - Epoch 73/200, Loss: 8.1067\n",
      "UserAE - Epoch 74/200, Loss: 8.2204\n",
      "UserAE - Epoch 75/200, Loss: 8.1771\n",
      "UserAE - Epoch 76/200, Loss: 8.1310\n",
      "UserAE - Epoch 77/200, Loss: 8.0979\n",
      "UserAE - Epoch 78/200, Loss: 8.0708\n",
      "UserAE - Epoch 79/200, Loss: 8.0657\n",
      "UserAE - Epoch 80/200, Loss: 8.1011\n",
      "UserAE - Epoch 81/200, Loss: 8.1015\n",
      "UserAE - Epoch 82/200, Loss: 8.1794\n",
      "UserAE - Epoch 83/200, Loss: 8.1344\n",
      "UserAE - Epoch 84/200, Loss: 8.0842\n",
      "UserAE - Epoch 85/200, Loss: 8.1578\n",
      "UserAE - Epoch 86/200, Loss: 8.0235\n",
      "UserAE - Epoch 87/200, Loss: 8.0110\n",
      "UserAE - Epoch 88/200, Loss: 8.1079\n",
      "UserAE - Epoch 89/200, Loss: 8.0464\n",
      "UserAE - Epoch 90/200, Loss: 8.0547\n",
      "UserAE - Epoch 91/200, Loss: 8.0249\n",
      "UserAE - Epoch 92/200, Loss: 8.0148\n",
      "UserAE - Epoch 93/200, Loss: 8.0207\n",
      "UserAE - Epoch 94/200, Loss: 8.0635\n",
      "UserAE - Epoch 95/200, Loss: 8.0400\n",
      "UserAE - Epoch 96/200, Loss: 8.1084\n",
      "UserAE - Epoch 97/200, Loss: 8.0238\n",
      "UserAE - Epoch 98/200, Loss: 7.9802\n",
      "UserAE - Epoch 99/200, Loss: 8.0015\n",
      "UserAE - Epoch 100/200, Loss: 8.0061\n",
      "UserAE - Epoch 101/200, Loss: 8.1290\n",
      "UserAE - Epoch 102/200, Loss: 8.0591\n",
      "UserAE - Epoch 103/200, Loss: 8.0294\n",
      "UserAE - Epoch 104/200, Loss: 8.0417\n",
      "UserAE - Epoch 105/200, Loss: 8.0513\n",
      "UserAE - Epoch 106/200, Loss: 7.9857\n",
      "UserAE - Epoch 107/200, Loss: 8.0193\n",
      "UserAE - Epoch 108/200, Loss: 8.0200\n",
      "UserAE - Epoch 109/200, Loss: 7.9975\n",
      "UserAE - Epoch 110/200, Loss: 8.0058\n",
      "UserAE - Epoch 111/200, Loss: 8.0131\n",
      "UserAE - Epoch 112/200, Loss: 7.9853\n",
      "UserAE - Epoch 113/200, Loss: 8.0692\n",
      "UserAE - Epoch 114/200, Loss: 8.0145\n",
      "UserAE - Epoch 115/200, Loss: 8.0835\n",
      "UserAE - Epoch 116/200, Loss: 8.0358\n",
      "UserAE - Epoch 117/200, Loss: 8.0148\n",
      "UserAE - Epoch 118/200, Loss: 7.9197\n",
      "UserAE - Epoch 119/200, Loss: 7.9476\n",
      "UserAE - Epoch 120/200, Loss: 7.9697\n",
      "UserAE - Epoch 121/200, Loss: 7.9665\n",
      "UserAE - Epoch 122/200, Loss: 8.0140\n",
      "UserAE - Epoch 123/200, Loss: 8.0247\n",
      "UserAE - Epoch 124/200, Loss: 7.9788\n",
      "UserAE - Epoch 125/200, Loss: 7.9997\n",
      "UserAE - Epoch 126/200, Loss: 8.0013\n",
      "UserAE - Epoch 127/200, Loss: 7.9457\n",
      "UserAE - Epoch 128/200, Loss: 8.0442\n",
      "UserAE - Epoch 129/200, Loss: 8.0492\n",
      "UserAE - Epoch 130/200, Loss: 8.0344\n",
      "UserAE - Epoch 131/200, Loss: 7.9988\n",
      "UserAE - Epoch 132/200, Loss: 7.9748\n",
      "UserAE - Epoch 133/200, Loss: 7.9203\n",
      "UserAE - Epoch 134/200, Loss: 7.9433\n",
      "UserAE - Epoch 135/200, Loss: 7.9727\n",
      "UserAE - Epoch 136/200, Loss: 7.9622\n",
      "UserAE - Epoch 137/200, Loss: 7.9525\n",
      "UserAE - Epoch 138/200, Loss: 7.9235\n",
      "UserAE - Epoch 139/200, Loss: 7.9589\n",
      "UserAE - Epoch 140/200, Loss: 7.9825\n",
      "UserAE - Epoch 141/200, Loss: 7.9178\n",
      "UserAE - Epoch 142/200, Loss: 8.0127\n",
      "UserAE - Epoch 143/200, Loss: 7.9770\n",
      "UserAE - Epoch 144/200, Loss: 8.0118\n",
      "UserAE - Epoch 145/200, Loss: 7.9624\n",
      "UserAE - Epoch 146/200, Loss: 7.9779\n",
      "UserAE - Epoch 147/200, Loss: 7.9707\n",
      "UserAE - Epoch 148/200, Loss: 8.0114\n",
      "UserAE - Epoch 149/200, Loss: 7.9592\n",
      "UserAE - Epoch 150/200, Loss: 7.9401\n",
      "UserAE - Epoch 151/200, Loss: 7.9374\n",
      "UserAE - Epoch 152/200, Loss: 7.9138\n",
      "UserAE - Epoch 153/200, Loss: 7.9273\n",
      "UserAE - Epoch 154/200, Loss: 8.0280\n",
      "UserAE - Epoch 155/200, Loss: 7.9486\n",
      "UserAE - Epoch 156/200, Loss: 7.9808\n",
      "UserAE - Epoch 157/200, Loss: 7.9229\n",
      "UserAE - Epoch 158/200, Loss: 7.9552\n",
      "UserAE - Epoch 159/200, Loss: 7.9195\n",
      "UserAE - Epoch 160/200, Loss: 7.9086\n",
      "UserAE - Epoch 161/200, Loss: 7.9324\n",
      "UserAE - Epoch 162/200, Loss: 7.9840\n",
      "UserAE - Epoch 163/200, Loss: 7.9596\n",
      "UserAE - Epoch 164/200, Loss: 7.9441\n",
      "UserAE - Epoch 165/200, Loss: 7.9389\n",
      "UserAE - Epoch 166/200, Loss: 7.9671\n",
      "UserAE - Epoch 167/200, Loss: 7.9772\n",
      "UserAE - Epoch 168/200, Loss: 7.9400\n",
      "UserAE - Epoch 169/200, Loss: 7.9542\n",
      "UserAE - Epoch 170/200, Loss: 7.9790\n",
      "UserAE - Epoch 171/200, Loss: 7.9628\n",
      "UserAE - Epoch 172/200, Loss: 7.9854\n",
      "UserAE - Epoch 173/200, Loss: 7.9302\n",
      "UserAE - Epoch 174/200, Loss: 7.9707\n",
      "UserAE - Epoch 175/200, Loss: 7.9205\n",
      "UserAE - Epoch 176/200, Loss: 7.8774\n",
      "UserAE - Epoch 177/200, Loss: 7.8640\n",
      "UserAE - Epoch 178/200, Loss: 7.8940\n",
      "UserAE - Epoch 179/200, Loss: 7.9504\n",
      "UserAE - Epoch 180/200, Loss: 8.0055\n",
      "UserAE - Epoch 181/200, Loss: 7.9452\n",
      "UserAE - Epoch 182/200, Loss: 7.8960\n",
      "UserAE - Epoch 183/200, Loss: 7.9395\n",
      "UserAE - Epoch 184/200, Loss: 7.9341\n",
      "UserAE - Epoch 185/200, Loss: 7.9956\n",
      "UserAE - Epoch 186/200, Loss: 7.9202\n",
      "UserAE - Epoch 187/200, Loss: 7.9002\n",
      "UserAE - Epoch 188/200, Loss: 7.9844\n",
      "UserAE - Epoch 189/200, Loss: 7.9055\n",
      "UserAE - Epoch 190/200, Loss: 7.9178\n",
      "UserAE - Epoch 191/200, Loss: 7.9330\n",
      "UserAE - Epoch 192/200, Loss: 7.8961\n",
      "UserAE - Epoch 193/200, Loss: 7.8960\n",
      "UserAE - Epoch 194/200, Loss: 7.8867\n",
      "UserAE - Epoch 195/200, Loss: 7.9337\n",
      "UserAE - Epoch 196/200, Loss: 7.9139\n",
      "UserAE - Epoch 197/200, Loss: 7.9937\n",
      "UserAE - Epoch 198/200, Loss: 7.8958\n",
      "UserAE - Epoch 199/200, Loss: 7.9729\n",
      "UserAE - Epoch 200/200, Loss: 7.9185\n",
      "ItemAE - Epoch 1/200, Loss: 33.6246\n",
      "ItemAE - Epoch 2/200, Loss: 24.8785\n",
      "ItemAE - Epoch 3/200, Loss: 22.5157\n",
      "ItemAE - Epoch 4/200, Loss: 21.0179\n",
      "ItemAE - Epoch 5/200, Loss: 20.1769\n",
      "ItemAE - Epoch 6/200, Loss: 19.6756\n",
      "ItemAE - Epoch 7/200, Loss: 19.0174\n",
      "ItemAE - Epoch 8/200, Loss: 18.6488\n",
      "ItemAE - Epoch 9/200, Loss: 18.2084\n",
      "ItemAE - Epoch 10/200, Loss: 18.0633\n",
      "ItemAE - Epoch 11/200, Loss: 17.7311\n",
      "ItemAE - Epoch 12/200, Loss: 17.6136\n",
      "ItemAE - Epoch 13/200, Loss: 17.6899\n",
      "ItemAE - Epoch 14/200, Loss: 17.4029\n",
      "ItemAE - Epoch 15/200, Loss: 17.1736\n",
      "ItemAE - Epoch 16/200, Loss: 16.9950\n",
      "ItemAE - Epoch 17/200, Loss: 16.9057\n",
      "ItemAE - Epoch 18/200, Loss: 17.0997\n",
      "ItemAE - Epoch 19/200, Loss: 16.8469\n",
      "ItemAE - Epoch 20/200, Loss: 16.6141\n",
      "ItemAE - Epoch 21/200, Loss: 16.6623\n",
      "ItemAE - Epoch 22/200, Loss: 16.5007\n",
      "ItemAE - Epoch 23/200, Loss: 16.5312\n",
      "ItemAE - Epoch 24/200, Loss: 16.2826\n",
      "ItemAE - Epoch 25/200, Loss: 16.4757\n",
      "ItemAE - Epoch 26/200, Loss: 16.6138\n",
      "ItemAE - Epoch 27/200, Loss: 16.5284\n",
      "ItemAE - Epoch 28/200, Loss: 16.4037\n",
      "ItemAE - Epoch 29/200, Loss: 16.3413\n",
      "ItemAE - Epoch 30/200, Loss: 16.1299\n",
      "ItemAE - Epoch 31/200, Loss: 16.2535\n",
      "ItemAE - Epoch 32/200, Loss: 16.1990\n",
      "ItemAE - Epoch 33/200, Loss: 16.2108\n",
      "ItemAE - Epoch 34/200, Loss: 16.1453\n",
      "ItemAE - Epoch 35/200, Loss: 16.0685\n",
      "ItemAE - Epoch 36/200, Loss: 16.1218\n",
      "ItemAE - Epoch 37/200, Loss: 15.9868\n",
      "ItemAE - Epoch 38/200, Loss: 15.9689\n",
      "ItemAE - Epoch 39/200, Loss: 16.0081\n",
      "ItemAE - Epoch 40/200, Loss: 15.8484\n",
      "ItemAE - Epoch 41/200, Loss: 15.9550\n",
      "ItemAE - Epoch 42/200, Loss: 15.8449\n",
      "ItemAE - Epoch 43/200, Loss: 15.7964\n",
      "ItemAE - Epoch 44/200, Loss: 15.9375\n",
      "ItemAE - Epoch 45/200, Loss: 15.8625\n",
      "ItemAE - Epoch 46/200, Loss: 15.7654\n",
      "ItemAE - Epoch 47/200, Loss: 15.7339\n",
      "ItemAE - Epoch 48/200, Loss: 15.8513\n",
      "ItemAE - Epoch 49/200, Loss: 15.7365\n",
      "ItemAE - Epoch 50/200, Loss: 15.6775\n",
      "ItemAE - Epoch 51/200, Loss: 15.7029\n",
      "ItemAE - Epoch 52/200, Loss: 15.6500\n",
      "ItemAE - Epoch 53/200, Loss: 15.7096\n",
      "ItemAE - Epoch 54/200, Loss: 15.8450\n",
      "ItemAE - Epoch 55/200, Loss: 15.7748\n",
      "ItemAE - Epoch 56/200, Loss: 15.7942\n",
      "ItemAE - Epoch 57/200, Loss: 15.7474\n",
      "ItemAE - Epoch 58/200, Loss: 15.6304\n",
      "ItemAE - Epoch 59/200, Loss: 15.6415\n",
      "ItemAE - Epoch 60/200, Loss: 15.7056\n",
      "ItemAE - Epoch 61/200, Loss: 15.6152\n",
      "ItemAE - Epoch 62/200, Loss: 15.6685\n",
      "ItemAE - Epoch 63/200, Loss: 15.6312\n",
      "ItemAE - Epoch 64/200, Loss: 15.6089\n",
      "ItemAE - Epoch 65/200, Loss: 15.5104\n",
      "ItemAE - Epoch 66/200, Loss: 15.5285\n",
      "ItemAE - Epoch 67/200, Loss: 15.5957\n",
      "ItemAE - Epoch 68/200, Loss: 15.6278\n",
      "ItemAE - Epoch 69/200, Loss: 15.5861\n",
      "ItemAE - Epoch 70/200, Loss: 15.6185\n",
      "ItemAE - Epoch 71/200, Loss: 15.5111\n",
      "ItemAE - Epoch 72/200, Loss: 15.5598\n",
      "ItemAE - Epoch 73/200, Loss: 15.6516\n",
      "ItemAE - Epoch 74/200, Loss: 15.6464\n",
      "ItemAE - Epoch 75/200, Loss: 15.5865\n",
      "ItemAE - Epoch 76/200, Loss: 15.4928\n",
      "ItemAE - Epoch 77/200, Loss: 15.4913\n",
      "ItemAE - Epoch 78/200, Loss: 15.5992\n",
      "ItemAE - Epoch 79/200, Loss: 15.5022\n",
      "ItemAE - Epoch 80/200, Loss: 15.3979\n",
      "ItemAE - Epoch 81/200, Loss: 15.5188\n",
      "ItemAE - Epoch 82/200, Loss: 15.5834\n",
      "ItemAE - Epoch 83/200, Loss: 15.5627\n",
      "ItemAE - Epoch 84/200, Loss: 15.4905\n",
      "ItemAE - Epoch 85/200, Loss: 15.4687\n",
      "ItemAE - Epoch 86/200, Loss: 15.5195\n",
      "ItemAE - Epoch 87/200, Loss: 15.4190\n",
      "ItemAE - Epoch 88/200, Loss: 15.5697\n",
      "ItemAE - Epoch 89/200, Loss: 15.4379\n",
      "ItemAE - Epoch 90/200, Loss: 15.5054\n",
      "ItemAE - Epoch 91/200, Loss: 15.4138\n",
      "ItemAE - Epoch 92/200, Loss: 15.5233\n",
      "ItemAE - Epoch 93/200, Loss: 15.4379\n",
      "ItemAE - Epoch 94/200, Loss: 15.5475\n",
      "ItemAE - Epoch 95/200, Loss: 15.4730\n",
      "ItemAE - Epoch 96/200, Loss: 15.4076\n",
      "ItemAE - Epoch 97/200, Loss: 15.4410\n",
      "ItemAE - Epoch 98/200, Loss: 15.3719\n",
      "ItemAE - Epoch 99/200, Loss: 15.3973\n",
      "ItemAE - Epoch 100/200, Loss: 15.4501\n",
      "ItemAE - Epoch 101/200, Loss: 15.4147\n",
      "ItemAE - Epoch 102/200, Loss: 15.3039\n",
      "ItemAE - Epoch 103/200, Loss: 15.5788\n",
      "ItemAE - Epoch 104/200, Loss: 15.4857\n",
      "ItemAE - Epoch 105/200, Loss: 15.5413\n",
      "ItemAE - Epoch 106/200, Loss: 15.3477\n",
      "ItemAE - Epoch 107/200, Loss: 15.5170\n",
      "ItemAE - Epoch 108/200, Loss: 15.4307\n",
      "ItemAE - Epoch 109/200, Loss: 15.3943\n",
      "ItemAE - Epoch 110/200, Loss: 15.4556\n",
      "ItemAE - Epoch 111/200, Loss: 15.3850\n",
      "ItemAE - Epoch 112/200, Loss: 15.3814\n",
      "ItemAE - Epoch 113/200, Loss: 15.4196\n",
      "ItemAE - Epoch 114/200, Loss: 15.4123\n",
      "ItemAE - Epoch 115/200, Loss: 15.2946\n",
      "ItemAE - Epoch 116/200, Loss: 15.2490\n",
      "ItemAE - Epoch 117/200, Loss: 15.3888\n",
      "ItemAE - Epoch 118/200, Loss: 15.3467\n",
      "ItemAE - Epoch 119/200, Loss: 15.4958\n",
      "ItemAE - Epoch 120/200, Loss: 15.3118\n",
      "ItemAE - Epoch 121/200, Loss: 15.3559\n",
      "ItemAE - Epoch 122/200, Loss: 15.4095\n",
      "ItemAE - Epoch 123/200, Loss: 15.3413\n",
      "ItemAE - Epoch 124/200, Loss: 15.3218\n",
      "ItemAE - Epoch 125/200, Loss: 15.2866\n",
      "ItemAE - Epoch 126/200, Loss: 15.2764\n",
      "ItemAE - Epoch 127/200, Loss: 15.2904\n",
      "ItemAE - Epoch 128/200, Loss: 15.4326\n",
      "ItemAE - Epoch 129/200, Loss: 15.3679\n",
      "ItemAE - Epoch 130/200, Loss: 15.2658\n",
      "ItemAE - Epoch 131/200, Loss: 15.2549\n",
      "ItemAE - Epoch 132/200, Loss: 15.3655\n",
      "ItemAE - Epoch 133/200, Loss: 15.3865\n",
      "ItemAE - Epoch 134/200, Loss: 15.3854\n",
      "ItemAE - Epoch 135/200, Loss: 15.4565\n",
      "ItemAE - Epoch 136/200, Loss: 15.3659\n",
      "ItemAE - Epoch 137/200, Loss: 15.4212\n",
      "ItemAE - Epoch 138/200, Loss: 15.3842\n",
      "ItemAE - Epoch 139/200, Loss: 15.4306\n",
      "ItemAE - Epoch 140/200, Loss: 15.3254\n",
      "ItemAE - Epoch 141/200, Loss: 15.3818\n",
      "ItemAE - Epoch 142/200, Loss: 15.3681\n",
      "ItemAE - Epoch 143/200, Loss: 15.3270\n",
      "ItemAE - Epoch 144/200, Loss: 15.4084\n",
      "ItemAE - Epoch 145/200, Loss: 15.1975\n",
      "ItemAE - Epoch 146/200, Loss: 15.4028\n",
      "ItemAE - Epoch 147/200, Loss: 15.2866\n",
      "ItemAE - Epoch 148/200, Loss: 15.3409\n",
      "ItemAE - Epoch 149/200, Loss: 15.2317\n",
      "ItemAE - Epoch 150/200, Loss: 15.4920\n",
      "ItemAE - Epoch 151/200, Loss: 15.3972\n",
      "ItemAE - Epoch 152/200, Loss: 15.3821\n",
      "ItemAE - Epoch 153/200, Loss: 15.3257\n",
      "ItemAE - Epoch 154/200, Loss: 15.2691\n",
      "ItemAE - Epoch 155/200, Loss: 15.3643\n",
      "ItemAE - Epoch 156/200, Loss: 15.3575\n",
      "ItemAE - Epoch 157/200, Loss: 15.2882\n",
      "ItemAE - Epoch 158/200, Loss: 15.3573\n",
      "ItemAE - Epoch 159/200, Loss: 15.4075\n",
      "ItemAE - Epoch 160/200, Loss: 15.4174\n",
      "ItemAE - Epoch 161/200, Loss: 15.3898\n",
      "ItemAE - Epoch 162/200, Loss: 15.3282\n",
      "ItemAE - Epoch 163/200, Loss: 15.3107\n",
      "ItemAE - Epoch 164/200, Loss: 15.4050\n",
      "ItemAE - Epoch 165/200, Loss: 15.4217\n",
      "ItemAE - Epoch 166/200, Loss: 15.4515\n",
      "ItemAE - Epoch 167/200, Loss: 15.4081\n",
      "ItemAE - Epoch 168/200, Loss: 15.3411\n",
      "ItemAE - Epoch 169/200, Loss: 15.3370\n",
      "ItemAE - Epoch 170/200, Loss: 15.3454\n",
      "ItemAE - Epoch 171/200, Loss: 15.3452\n",
      "ItemAE - Epoch 172/200, Loss: 15.3582\n",
      "ItemAE - Epoch 173/200, Loss: 15.5559\n",
      "ItemAE - Epoch 174/200, Loss: 15.4821\n",
      "ItemAE - Epoch 175/200, Loss: 15.2425\n",
      "ItemAE - Epoch 176/200, Loss: 15.3752\n",
      "ItemAE - Epoch 177/200, Loss: 15.2151\n",
      "ItemAE - Epoch 178/200, Loss: 15.3198\n",
      "ItemAE - Epoch 179/200, Loss: 15.3291\n",
      "ItemAE - Epoch 180/200, Loss: 15.2312\n",
      "ItemAE - Epoch 181/200, Loss: 15.2296\n",
      "ItemAE - Epoch 182/200, Loss: 15.3846\n",
      "ItemAE - Epoch 183/200, Loss: 15.4307\n",
      "ItemAE - Epoch 184/200, Loss: 15.2494\n",
      "ItemAE - Epoch 185/200, Loss: 15.3480\n",
      "ItemAE - Epoch 186/200, Loss: 15.3001\n",
      "ItemAE - Epoch 187/200, Loss: 15.2872\n",
      "ItemAE - Epoch 188/200, Loss: 15.2579\n",
      "ItemAE - Epoch 189/200, Loss: 15.2155\n",
      "ItemAE - Epoch 190/200, Loss: 15.3653\n",
      "ItemAE - Epoch 191/200, Loss: 15.3724\n",
      "ItemAE - Epoch 192/200, Loss: 15.3018\n",
      "ItemAE - Epoch 193/200, Loss: 15.2315\n",
      "ItemAE - Epoch 194/200, Loss: 15.4717\n",
      "ItemAE - Epoch 195/200, Loss: 15.3028\n",
      "ItemAE - Epoch 196/200, Loss: 15.2419\n",
      "ItemAE - Epoch 197/200, Loss: 15.3345\n",
      "ItemAE - Epoch 198/200, Loss: 15.3049\n",
      "ItemAE - Epoch 199/200, Loss: 15.3043\n",
      "ItemAE - Epoch 200/200, Loss: 15.2029\n",
      "Initial Evaluation -> RMSE: 1.8664, MAE: 1.4691\n",
      "Matrix Factorization - Epoch 1/20, RMSE: 1.8666, MAE: 1.4692, V Norm: 9.8652\n",
      "Matrix Factorization - Epoch 2/20, RMSE: 1.8672, MAE: 1.4698, V Norm: 9.8617\n",
      "Matrix Factorization - Epoch 3/20, RMSE: 1.8673, MAE: 1.4699, V Norm: 9.8587\n",
      "Matrix Factorization - Epoch 4/20, RMSE: 1.8666, MAE: 1.4692, V Norm: 9.8556\n",
      "Matrix Factorization - Epoch 5/20, RMSE: 1.8676, MAE: 1.4701, V Norm: 9.8532\n",
      "Matrix Factorization - Epoch 6/20, RMSE: 1.8685, MAE: 1.4709, V Norm: 9.8512\n",
      "Matrix Factorization - Epoch 7/20, RMSE: 1.8693, MAE: 1.4716, V Norm: 9.8481\n",
      "Matrix Factorization - Epoch 8/20, RMSE: 1.8709, MAE: 1.4726, V Norm: 9.8457\n",
      "Matrix Factorization - Epoch 9/20, RMSE: 1.8716, MAE: 1.4732, V Norm: 9.8436\n",
      "Matrix Factorization - Epoch 10/20, RMSE: 1.8726, MAE: 1.4744, V Norm: 9.8415\n",
      "Matrix Factorization - Epoch 11/20, RMSE: 1.8733, MAE: 1.4753, V Norm: 9.8391\n",
      "Matrix Factorization - Epoch 12/20, RMSE: 1.8739, MAE: 1.4759, V Norm: 9.8365\n",
      "Matrix Factorization - Epoch 13/20, RMSE: 1.8750, MAE: 1.4773, V Norm: 9.8347\n",
      "Matrix Factorization - Epoch 14/20, RMSE: 1.8759, MAE: 1.4780, V Norm: 9.8330\n",
      "Matrix Factorization - Epoch 15/20, RMSE: 1.8766, MAE: 1.4786, V Norm: 9.8303\n",
      "Matrix Factorization - Epoch 16/20, RMSE: 1.8774, MAE: 1.4794, V Norm: 9.8276\n",
      "Matrix Factorization - Epoch 17/20, RMSE: 1.8786, MAE: 1.4807, V Norm: 9.8257\n",
      "Matrix Factorization - Epoch 18/20, RMSE: 1.8787, MAE: 1.4807, V Norm: 9.8240\n",
      "Matrix Factorization - Epoch 19/20, RMSE: 1.8792, MAE: 1.4809, V Norm: 9.8216\n",
      "Matrix Factorization - Epoch 20/20, RMSE: 1.8791, MAE: 1.4807, V Norm: 9.8192\n",
      "Final Evaluation -> RMSE: 1.8791, MAE: 1.4807\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load MovieLens 100K data\n",
    "ratings_train = pd.read_csv('ml-100k/u1.base', sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "ratings_test = pd.read_csv('ml-100k/u1.test', sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "items = pd.read_csv('ml-100k/u.item', sep='|', encoding='latin-1', header=None)\n",
    "P = items.iloc[:, 5:24].values  # Item features (genres), shape (num_items, 19)\n",
    "\n",
    "# Get dimensions\n",
    "num_users = max(ratings_train['user_id'].max(), ratings_test['user_id'].max())\n",
    "num_items = max(ratings_train['item_id'].max(), ratings_test['item_id'].max())\n",
    "\n",
    "# Create rating matrix R with missing values as 0\n",
    "R = np.zeros((num_users, num_items))\n",
    "for row in ratings_train.itertuples():\n",
    "    R[row.user_id - 1, row.item_id - 1] = row.rating\n",
    "\n",
    "# Create mask for observed ratings in training set\n",
    "mask_train = np.zeros((num_users, num_items), dtype=bool)\n",
    "for row in ratings_train.itertuples():\n",
    "    mask_train[row.user_id - 1, row.item_id - 1] = True\n",
    "\n",
    "# Define User Autoencoder\n",
    "class UserAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(UserAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Linear(input_dim, hidden_dim)\n",
    "        self.decoder = nn.Linear(hidden_dim, input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = F.relu(self.encoder(x))\n",
    "        output = self.decoder(z)\n",
    "        output = 1 + 4 * torch.sigmoid(output)  # Scale to [1, 5]\n",
    "        return output\n",
    "\n",
    "# Define Item Autoencoder\n",
    "class ItemAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim_user_ratings, input_dim_item_features, hidden_dim):\n",
    "        super(ItemAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Linear(input_dim_user_ratings + input_dim_item_features, hidden_dim)\n",
    "        self.decoder = nn.Linear(hidden_dim, input_dim_user_ratings)\n",
    "\n",
    "    def forward(self, x_ratings, x_features):\n",
    "        x = torch.cat([x_ratings, x_features], dim=1)\n",
    "        z = F.relu(self.encoder(x))\n",
    "        output = self.decoder(z)\n",
    "        output = 1 + 4 * torch.sigmoid(output)  # Scale to [1, 5]\n",
    "        return output\n",
    "\n",
    "# Define datasets\n",
    "class UserDataset(Dataset):\n",
    "    def __init__(self, R, mask):\n",
    "        self.R = R\n",
    "        self.mask = mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.R)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.R[idx], dtype=torch.float32), torch.tensor(self.mask[idx], dtype=torch.bool)\n",
    "\n",
    "class ItemDataset(Dataset):\n",
    "    def __init__(self, R, P, mask):\n",
    "        self.R = R.T  # (num_items, num_users)\n",
    "        self.P = P  # (num_items, num_features)\n",
    "        self.mask = mask.T  # (num_items, num_users)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.R)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.R[idx], dtype=torch.float32), torch.tensor(self.P[idx], dtype=torch.float32), torch.tensor(self.mask[idx], dtype=torch.bool)\n",
    "\n",
    "# Training function for autoencoders\n",
    "def train_autoencoder(model, dataloader, num_epochs, learning_rate, model_name):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.01)  # Use Adam with weight decay\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        for data in dataloader:\n",
    "            if len(data) == 2:\n",
    "                x, m = data\n",
    "                x = x.to(device)\n",
    "                m = m.to(device)\n",
    "                output = model(x)\n",
    "                loss = F.mse_loss(output[m], x[m], reduction='sum') / m.sum()  # Normalize by number of observed ratings\n",
    "            else:\n",
    "                x_ratings, x_features, m = data\n",
    "                x_ratings = x_ratings.to(device)\n",
    "                x_features = x_features.to(device)\n",
    "                m = m.to(device)\n",
    "                output = model(x_ratings, x_features)\n",
    "                loss = F.mse_loss(output[m], x_ratings[m], reduction='sum') / m.sum()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"{model_name} - Epoch {epoch+1}/{num_epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyperparameters\n",
    "d = 150  # Increased latent dimension\n",
    "learning_rate = 0.001  # Lower learning rate\n",
    "num_epochs = 200  # More epochs\n",
    "learning_rate_mf = 0.0005  # Lower learning rate for MF\n",
    "num_epochs_mf = 20  # More epochs for MF\n",
    "C = 1.0  # Gradient clipping norm\n",
    "epsilon = 5.0  # Total privacy budget\n",
    "lambda_v = 0.1  # Increased regularization\n",
    "b = C / (epsilon / num_epochs_mf)  # Adjusted noise scale for more epochs\n",
    "\n",
    "# Train user autoencoder\n",
    "model_user = UserAutoencoder(input_dim=num_items, hidden_dim=d).to(device)\n",
    "dataset_user = UserDataset(R=R, mask=mask_train)\n",
    "dataloader_user = DataLoader(dataset_user, batch_size=64, shuffle=True)  # Larger batch size\n",
    "train_autoencoder(model_user, dataloader_user, num_epochs, learning_rate, model_name=\"UserAE\")\n",
    "\n",
    "# Train item autoencoder\n",
    "model_item = ItemAutoencoder(input_dim_user_ratings=num_users, input_dim_item_features=19, hidden_dim=d).to(device)\n",
    "dataset_item = ItemDataset(R=R, P=P, mask=mask_train)\n",
    "dataloader_item = DataLoader(dataset_item, batch_size=64, shuffle=True)\n",
    "train_autoencoder(model_item, dataloader_item, num_epochs, learning_rate, model_name=\"ItemAE\")\n",
    "\n",
    "# Extract latent factors\n",
    "with torch.no_grad():\n",
    "    R_tensor = torch.tensor(R, dtype=torch.float32).to(device)\n",
    "    U = model_user.encoder(R_tensor).cpu().numpy()  # User latent factors\n",
    "    item_inputs = np.concatenate([R.T, P], axis=1)\n",
    "    item_inputs_tensor = torch.tensor(item_inputs, dtype=torch.float32).to(device)\n",
    "    V = model_item.encoder(item_inputs_tensor).cpu().numpy()  # Initial item latent factors\n",
    "\n",
    "# Evaluate function for test set\n",
    "def evaluate(U, V, ratings_test):\n",
    "    test_pred = []\n",
    "    test_true = []\n",
    "    for row in ratings_test.itertuples():\n",
    "        i = row.user_id - 1\n",
    "        j = row.item_id - 1\n",
    "        pred = np.dot(U[i], V[j])\n",
    "        pred = np.clip(pred, 1, 5)  # Clip predictions to [1, 5]\n",
    "        test_pred.append(pred)\n",
    "        test_true.append(row.rating)\n",
    "    rmse = np.sqrt(mean_squared_error(test_true, test_pred))\n",
    "    mae = mean_absolute_error(test_true, test_pred)\n",
    "    return rmse, mae\n",
    "\n",
    "# Initial evaluation\n",
    "initial_rmse, initial_mae = evaluate(U, V, ratings_test)\n",
    "print(f\"Initial Evaluation -> RMSE: {initial_rmse:.4f}, MAE: {initial_mae:.4f}\")\n",
    "\n",
    "# Train V with differentially private SGD, with logging\n",
    "rmse_values = [initial_rmse]\n",
    "mae_values = [initial_mae]\n",
    "v_norms = [np.linalg.norm(V, axis=1).mean()]\n",
    "\n",
    "for epoch in range(num_epochs_mf):\n",
    "    shuffled_ratings_train = ratings_train.sample(frac=1).reset_index(drop=True)\n",
    "    for row in shuffled_ratings_train.itertuples():\n",
    "        i = row.user_id - 1\n",
    "        j = row.item_id - 1\n",
    "        r = row.rating\n",
    "        pred = np.dot(U[i], V[j])\n",
    "        # Only update for observed ratings\n",
    "        if mask_train[i, j]:\n",
    "            e = r - pred\n",
    "        else:\n",
    "            e = 0\n",
    "        g_j = -2 * e * U[i] + lambda_v * V[j]  # Gradient\n",
    "        norm_g_j = np.linalg.norm(g_j)\n",
    "        if norm_g_j > C:\n",
    "            g_j = g_j * (C / norm_g_j)  # Clip gradient\n",
    "        noise = np.random.laplace(0, b, size=d)  # Add Laplace noise\n",
    "        g_j_noisy = g_j + noise\n",
    "        V[j] -= learning_rate_mf * g_j_noisy  # Update V\n",
    "    rmse, mae = evaluate(U, V, ratings_test)\n",
    "    rmse_values.append(rmse)\n",
    "    mae_values.append(mae)\n",
    "    v_norms.append(np.linalg.norm(V, axis=1).mean())\n",
    "    print(f\"Matrix Factorization - Epoch {epoch+1}/{num_epochs_mf}, RMSE: {rmse:.4f}, MAE: {mae:.4f}, V Norm: {v_norms[-1]:.4f}\")\n",
    "\n",
    "# Final evaluation\n",
    "final_rmse, final_mae = evaluate(U, V, ratings_test)\n",
    "print(f\"Final Evaluation -> RMSE: {final_rmse:.4f}, MAE: {final_mae:.4f}\")\n",
    "\n",
    "# Visualizations\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot 1: RMSE Over Epochs\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(range(num_epochs_mf + 1), rmse_values, marker='o', label='RMSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE Over Epochs')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Plot 2: MAE Over Epochs\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(range(num_epochs_mf + 1), mae_values, marker='o', label='MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.title('MAE Over Epochs')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Plot 3: V Norm Over Epochs\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(range(num_epochs_mf + 1), v_norms, marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average V Norm')\n",
    "plt.title('V Norm Over Epochs')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('dp_ae_metrics_corrected.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenoisingUserAE - Epoch 1/100, Loss: 18.7647\n",
      "DenoisingUserAE - Epoch 2/100, Loss: 15.9911\n",
      "DenoisingUserAE - Epoch 3/100, Loss: 15.2712\n",
      "DenoisingUserAE - Epoch 4/100, Loss: 15.2605\n",
      "DenoisingUserAE - Epoch 5/100, Loss: 14.8403\n",
      "DenoisingUserAE - Epoch 6/100, Loss: 14.8521\n",
      "DenoisingUserAE - Epoch 7/100, Loss: 14.5417\n",
      "DenoisingUserAE - Epoch 8/100, Loss: 14.0957\n",
      "DenoisingUserAE - Epoch 9/100, Loss: 14.0395\n",
      "DenoisingUserAE - Epoch 10/100, Loss: 13.8789\n",
      "DenoisingUserAE - Epoch 11/100, Loss: 13.9282\n",
      "DenoisingUserAE - Epoch 12/100, Loss: 13.9193\n",
      "DenoisingUserAE - Epoch 13/100, Loss: 13.8398\n",
      "DenoisingUserAE - Epoch 14/100, Loss: 13.7102\n",
      "DenoisingUserAE - Epoch 15/100, Loss: 13.7940\n",
      "DenoisingUserAE - Epoch 16/100, Loss: 13.7838\n",
      "DenoisingUserAE - Epoch 17/100, Loss: 13.5865\n",
      "DenoisingUserAE - Epoch 18/100, Loss: 13.6070\n",
      "DenoisingUserAE - Epoch 19/100, Loss: 13.5761\n",
      "DenoisingUserAE - Epoch 20/100, Loss: 13.7141\n",
      "DenoisingUserAE - Epoch 21/100, Loss: 13.6900\n",
      "DenoisingUserAE - Epoch 22/100, Loss: 13.6265\n",
      "DenoisingUserAE - Epoch 23/100, Loss: 13.5391\n",
      "DenoisingUserAE - Epoch 24/100, Loss: 13.4910\n",
      "DenoisingUserAE - Epoch 25/100, Loss: 13.4085\n",
      "DenoisingUserAE - Epoch 26/100, Loss: 13.5237\n",
      "DenoisingUserAE - Epoch 27/100, Loss: 13.4955\n",
      "DenoisingUserAE - Epoch 28/100, Loss: 13.5145\n",
      "DenoisingUserAE - Epoch 29/100, Loss: 13.5870\n",
      "DenoisingUserAE - Epoch 30/100, Loss: 13.4485\n",
      "DenoisingUserAE - Epoch 31/100, Loss: 13.4551\n",
      "DenoisingUserAE - Epoch 32/100, Loss: 13.2325\n",
      "DenoisingUserAE - Epoch 33/100, Loss: 13.3500\n",
      "DenoisingUserAE - Epoch 34/100, Loss: 13.2864\n",
      "DenoisingUserAE - Epoch 35/100, Loss: 13.4008\n",
      "DenoisingUserAE - Epoch 36/100, Loss: 13.3355\n",
      "DenoisingUserAE - Epoch 37/100, Loss: 13.2201\n",
      "DenoisingUserAE - Epoch 38/100, Loss: 13.2742\n",
      "DenoisingUserAE - Epoch 39/100, Loss: 13.2599\n",
      "DenoisingUserAE - Epoch 40/100, Loss: 13.4075\n",
      "DenoisingUserAE - Epoch 41/100, Loss: 13.4715\n",
      "DenoisingUserAE - Epoch 42/100, Loss: 13.3488\n",
      "DenoisingUserAE - Epoch 43/100, Loss: 13.2306\n",
      "DenoisingUserAE - Epoch 44/100, Loss: 13.2723\n",
      "DenoisingUserAE - Epoch 45/100, Loss: 13.3441\n",
      "DenoisingUserAE - Epoch 46/100, Loss: 13.1942\n",
      "DenoisingUserAE - Epoch 47/100, Loss: 13.1174\n",
      "DenoisingUserAE - Epoch 48/100, Loss: 13.1525\n",
      "DenoisingUserAE - Epoch 49/100, Loss: 13.1607\n",
      "DenoisingUserAE - Epoch 50/100, Loss: 13.2097\n",
      "DenoisingUserAE - Epoch 51/100, Loss: 13.0015\n",
      "DenoisingUserAE - Epoch 52/100, Loss: 13.0097\n",
      "DenoisingUserAE - Epoch 53/100, Loss: 12.9507\n",
      "DenoisingUserAE - Epoch 54/100, Loss: 13.0867\n",
      "DenoisingUserAE - Epoch 55/100, Loss: 13.2991\n",
      "DenoisingUserAE - Epoch 56/100, Loss: 13.1271\n",
      "DenoisingUserAE - Epoch 57/100, Loss: 12.8734\n",
      "DenoisingUserAE - Epoch 58/100, Loss: 12.9850\n",
      "DenoisingUserAE - Epoch 59/100, Loss: 12.9364\n",
      "DenoisingUserAE - Epoch 60/100, Loss: 12.9076\n",
      "DenoisingUserAE - Epoch 61/100, Loss: 12.8783\n",
      "DenoisingUserAE - Epoch 62/100, Loss: 12.8584\n",
      "DenoisingUserAE - Epoch 63/100, Loss: 12.9694\n",
      "DenoisingUserAE - Epoch 64/100, Loss: 12.8741\n",
      "DenoisingUserAE - Epoch 65/100, Loss: 12.8910\n",
      "DenoisingUserAE - Epoch 66/100, Loss: 12.8497\n",
      "DenoisingUserAE - Epoch 67/100, Loss: 12.7802\n",
      "DenoisingUserAE - Epoch 68/100, Loss: 12.8371\n",
      "DenoisingUserAE - Epoch 69/100, Loss: 12.7585\n",
      "DenoisingUserAE - Epoch 70/100, Loss: 12.9297\n",
      "DenoisingUserAE - Epoch 71/100, Loss: 12.7373\n",
      "DenoisingUserAE - Epoch 72/100, Loss: 12.6936\n",
      "DenoisingUserAE - Epoch 73/100, Loss: 12.7834\n",
      "DenoisingUserAE - Epoch 74/100, Loss: 12.7129\n",
      "DenoisingUserAE - Epoch 75/100, Loss: 12.7195\n",
      "DenoisingUserAE - Epoch 76/100, Loss: 12.6653\n",
      "DenoisingUserAE - Epoch 77/100, Loss: 12.6556\n",
      "DenoisingUserAE - Epoch 78/100, Loss: 12.5881\n",
      "DenoisingUserAE - Epoch 79/100, Loss: 12.7432\n",
      "DenoisingUserAE - Epoch 80/100, Loss: 12.7131\n",
      "DenoisingUserAE - Epoch 81/100, Loss: 12.7245\n",
      "DenoisingUserAE - Epoch 82/100, Loss: 12.6356\n",
      "DenoisingUserAE - Epoch 83/100, Loss: 12.5404\n",
      "DenoisingUserAE - Epoch 84/100, Loss: 12.5674\n",
      "DenoisingUserAE - Epoch 85/100, Loss: 12.5394\n",
      "DenoisingUserAE - Epoch 86/100, Loss: 12.6160\n",
      "DenoisingUserAE - Epoch 87/100, Loss: 12.6957\n",
      "DenoisingUserAE - Epoch 88/100, Loss: 12.6256\n",
      "DenoisingUserAE - Epoch 89/100, Loss: 12.5720\n",
      "DenoisingUserAE - Epoch 90/100, Loss: 12.5729\n",
      "DenoisingUserAE - Epoch 91/100, Loss: 12.6078\n",
      "DenoisingUserAE - Epoch 92/100, Loss: 12.5466\n",
      "DenoisingUserAE - Epoch 93/100, Loss: 12.5489\n",
      "DenoisingUserAE - Epoch 94/100, Loss: 12.5230\n",
      "DenoisingUserAE - Epoch 95/100, Loss: 12.5857\n",
      "DenoisingUserAE - Epoch 96/100, Loss: 12.6410\n",
      "DenoisingUserAE - Epoch 97/100, Loss: 12.5858\n",
      "DenoisingUserAE - Epoch 98/100, Loss: 12.4831\n",
      "DenoisingUserAE - Epoch 99/100, Loss: 12.5108\n",
      "DenoisingUserAE - Epoch 100/100, Loss: 12.4969\n",
      "DenoisingItemAE - Epoch 1/100, Loss: 30.4391\n",
      "DenoisingItemAE - Epoch 2/100, Loss: 26.3389\n",
      "DenoisingItemAE - Epoch 3/100, Loss: 25.8081\n",
      "DenoisingItemAE - Epoch 4/100, Loss: 24.9468\n",
      "DenoisingItemAE - Epoch 5/100, Loss: 24.3547\n",
      "DenoisingItemAE - Epoch 6/100, Loss: 24.3112\n",
      "DenoisingItemAE - Epoch 7/100, Loss: 23.7275\n",
      "DenoisingItemAE - Epoch 8/100, Loss: 23.3971\n",
      "DenoisingItemAE - Epoch 9/100, Loss: 23.2263\n",
      "DenoisingItemAE - Epoch 10/100, Loss: 22.8736\n",
      "DenoisingItemAE - Epoch 11/100, Loss: 22.8718\n",
      "DenoisingItemAE - Epoch 12/100, Loss: 22.9279\n",
      "DenoisingItemAE - Epoch 13/100, Loss: 22.9052\n",
      "DenoisingItemAE - Epoch 14/100, Loss: 22.8940\n",
      "DenoisingItemAE - Epoch 15/100, Loss: 22.8070\n",
      "DenoisingItemAE - Epoch 16/100, Loss: 22.8784\n",
      "DenoisingItemAE - Epoch 17/100, Loss: 22.6219\n",
      "DenoisingItemAE - Epoch 18/100, Loss: 22.5764\n",
      "DenoisingItemAE - Epoch 19/100, Loss: 22.6079\n",
      "DenoisingItemAE - Epoch 20/100, Loss: 22.4003\n",
      "DenoisingItemAE - Epoch 21/100, Loss: 22.4876\n",
      "DenoisingItemAE - Epoch 22/100, Loss: 22.3159\n",
      "DenoisingItemAE - Epoch 23/100, Loss: 22.5143\n",
      "DenoisingItemAE - Epoch 24/100, Loss: 22.6825\n",
      "DenoisingItemAE - Epoch 25/100, Loss: 22.3826\n",
      "DenoisingItemAE - Epoch 26/100, Loss: 22.2738\n",
      "DenoisingItemAE - Epoch 27/100, Loss: 22.2639\n",
      "DenoisingItemAE - Epoch 28/100, Loss: 22.1403\n",
      "DenoisingItemAE - Epoch 29/100, Loss: 22.2220\n",
      "DenoisingItemAE - Epoch 30/100, Loss: 22.3054\n",
      "DenoisingItemAE - Epoch 31/100, Loss: 22.1684\n",
      "DenoisingItemAE - Epoch 32/100, Loss: 22.2158\n",
      "DenoisingItemAE - Epoch 33/100, Loss: 22.1968\n",
      "DenoisingItemAE - Epoch 34/100, Loss: 22.1578\n",
      "DenoisingItemAE - Epoch 35/100, Loss: 22.0747\n",
      "DenoisingItemAE - Epoch 36/100, Loss: 22.1043\n",
      "DenoisingItemAE - Epoch 37/100, Loss: 22.0916\n",
      "DenoisingItemAE - Epoch 38/100, Loss: 22.0950\n",
      "DenoisingItemAE - Epoch 39/100, Loss: 22.0178\n",
      "DenoisingItemAE - Epoch 40/100, Loss: 21.9370\n",
      "DenoisingItemAE - Epoch 41/100, Loss: 22.1636\n",
      "DenoisingItemAE - Epoch 42/100, Loss: 22.0479\n",
      "DenoisingItemAE - Epoch 43/100, Loss: 21.9547\n",
      "DenoisingItemAE - Epoch 44/100, Loss: 22.1080\n",
      "DenoisingItemAE - Epoch 45/100, Loss: 22.2920\n",
      "DenoisingItemAE - Epoch 46/100, Loss: 22.0489\n",
      "DenoisingItemAE - Epoch 47/100, Loss: 22.0710\n",
      "DenoisingItemAE - Epoch 48/100, Loss: 21.8674\n",
      "DenoisingItemAE - Epoch 49/100, Loss: 22.1916\n",
      "DenoisingItemAE - Epoch 50/100, Loss: 22.0066\n",
      "DenoisingItemAE - Epoch 51/100, Loss: 21.9024\n",
      "DenoisingItemAE - Epoch 52/100, Loss: 21.9582\n",
      "DenoisingItemAE - Epoch 53/100, Loss: 21.7999\n",
      "DenoisingItemAE - Epoch 54/100, Loss: 21.9589\n",
      "DenoisingItemAE - Epoch 55/100, Loss: 21.9595\n",
      "DenoisingItemAE - Epoch 56/100, Loss: 22.0919\n",
      "DenoisingItemAE - Epoch 57/100, Loss: 21.9145\n",
      "DenoisingItemAE - Epoch 58/100, Loss: 21.8577\n",
      "DenoisingItemAE - Epoch 59/100, Loss: 22.0193\n",
      "DenoisingItemAE - Epoch 60/100, Loss: 21.9891\n",
      "DenoisingItemAE - Epoch 61/100, Loss: 21.8560\n",
      "DenoisingItemAE - Epoch 62/100, Loss: 21.7850\n",
      "DenoisingItemAE - Epoch 63/100, Loss: 21.8463\n",
      "DenoisingItemAE - Epoch 64/100, Loss: 21.7870\n",
      "DenoisingItemAE - Epoch 65/100, Loss: 21.7456\n",
      "DenoisingItemAE - Epoch 66/100, Loss: 21.7980\n",
      "DenoisingItemAE - Epoch 67/100, Loss: 21.7501\n",
      "DenoisingItemAE - Epoch 68/100, Loss: 21.8802\n",
      "DenoisingItemAE - Epoch 69/100, Loss: 21.8427\n",
      "DenoisingItemAE - Epoch 70/100, Loss: 21.8144\n",
      "DenoisingItemAE - Epoch 71/100, Loss: 21.7936\n",
      "DenoisingItemAE - Epoch 72/100, Loss: 21.7838\n",
      "DenoisingItemAE - Epoch 73/100, Loss: 21.8355\n",
      "DenoisingItemAE - Epoch 74/100, Loss: 21.7156\n",
      "DenoisingItemAE - Epoch 75/100, Loss: 21.7894\n",
      "DenoisingItemAE - Epoch 76/100, Loss: 21.6595\n",
      "DenoisingItemAE - Epoch 77/100, Loss: 21.8506\n",
      "DenoisingItemAE - Epoch 78/100, Loss: 21.6900\n",
      "DenoisingItemAE - Epoch 79/100, Loss: 21.6930\n",
      "DenoisingItemAE - Epoch 80/100, Loss: 21.6330\n",
      "DenoisingItemAE - Epoch 81/100, Loss: 21.8770\n",
      "DenoisingItemAE - Epoch 82/100, Loss: 21.6272\n",
      "DenoisingItemAE - Epoch 83/100, Loss: 21.8322\n",
      "DenoisingItemAE - Epoch 84/100, Loss: 21.7140\n",
      "DenoisingItemAE - Epoch 85/100, Loss: 21.6036\n",
      "DenoisingItemAE - Epoch 86/100, Loss: 21.5929\n",
      "DenoisingItemAE - Epoch 87/100, Loss: 21.5520\n",
      "DenoisingItemAE - Epoch 88/100, Loss: 21.6242\n",
      "DenoisingItemAE - Epoch 89/100, Loss: 21.7245\n",
      "DenoisingItemAE - Epoch 90/100, Loss: 21.5698\n",
      "DenoisingItemAE - Epoch 91/100, Loss: 21.6421\n",
      "DenoisingItemAE - Epoch 92/100, Loss: 21.6935\n",
      "DenoisingItemAE - Epoch 93/100, Loss: 21.8787\n",
      "DenoisingItemAE - Epoch 94/100, Loss: 21.6559\n",
      "DenoisingItemAE - Epoch 95/100, Loss: 21.6613\n",
      "DenoisingItemAE - Epoch 96/100, Loss: 21.5506\n",
      "DenoisingItemAE - Epoch 97/100, Loss: 21.7019\n",
      "DenoisingItemAE - Epoch 98/100, Loss: 21.7298\n",
      "DenoisingItemAE - Epoch 99/100, Loss: 21.5760\n",
      "DenoisingItemAE - Epoch 100/100, Loss: 21.6215\n",
      "Initial Evaluation -> RMSE: 1.8555, MAE: 1.4574\n",
      "Matrix Factorization - Epoch 1/30, Avg Gradient Norm: 798.5475, Noise Scale: 4.7860, RMSE: 1.8552, MAE: 1.4572, V Norm: 8.0538\n",
      "Matrix Factorization - Epoch 2/30, Avg Gradient Norm: 795.8428, Noise Scale: 4.4927, RMSE: 1.8550, MAE: 1.4570, V Norm: 8.0440\n",
      "Matrix Factorization - Epoch 3/30, Avg Gradient Norm: 793.0698, Noise Scale: 4.1961, RMSE: 1.8548, MAE: 1.4569, V Norm: 8.0328\n",
      "Matrix Factorization - Epoch 4/30, Avg Gradient Norm: 790.2010, Noise Scale: 3.9559, RMSE: 1.8545, MAE: 1.4567, V Norm: 8.0214\n",
      "Matrix Factorization - Epoch 5/30, Avg Gradient Norm: 787.1061, Noise Scale: 3.7368, RMSE: 1.8542, MAE: 1.4564, V Norm: 8.0092\n",
      "Matrix Factorization - Epoch 6/30, Avg Gradient Norm: 783.8717, Noise Scale: 3.5291, RMSE: 1.8538, MAE: 1.4562, V Norm: 7.9970\n",
      "Matrix Factorization - Epoch 7/30, Avg Gradient Norm: 780.6205, Noise Scale: 3.3383, RMSE: 1.8536, MAE: 1.4560, V Norm: 7.9857\n",
      "Matrix Factorization - Epoch 8/30, Avg Gradient Norm: 777.3087, Noise Scale: 3.1885, RMSE: 1.8531, MAE: 1.4557, V Norm: 7.9739\n",
      "Matrix Factorization - Epoch 9/30, Avg Gradient Norm: 773.8336, Noise Scale: 3.0270, RMSE: 1.8528, MAE: 1.4555, V Norm: 7.9628\n",
      "Matrix Factorization - Epoch 10/30, Avg Gradient Norm: 770.3102, Noise Scale: 2.8811, RMSE: 1.8525, MAE: 1.4552, V Norm: 7.9507\n",
      "Matrix Factorization - Epoch 11/30, Avg Gradient Norm: 766.6988, Noise Scale: 2.7634, RMSE: 1.8521, MAE: 1.4549, V Norm: 7.9384\n",
      "Matrix Factorization - Epoch 12/30, Avg Gradient Norm: 762.9181, Noise Scale: 2.6440, RMSE: 1.8517, MAE: 1.4545, V Norm: 7.9258\n",
      "Matrix Factorization - Epoch 13/30, Avg Gradient Norm: 758.9648, Noise Scale: 2.5329, RMSE: 1.8511, MAE: 1.4541, V Norm: 7.9134\n",
      "Matrix Factorization - Epoch 14/30, Avg Gradient Norm: 754.9032, Noise Scale: 2.4279, RMSE: 1.8508, MAE: 1.4537, V Norm: 7.9009\n",
      "Matrix Factorization - Epoch 15/30, Avg Gradient Norm: 750.6779, Noise Scale: 2.3335, RMSE: 1.8503, MAE: 1.4534, V Norm: 7.8890\n",
      "Matrix Factorization - Epoch 16/30, Avg Gradient Norm: 746.2661, Noise Scale: 2.2463, RMSE: 1.8498, MAE: 1.4529, V Norm: 7.8769\n",
      "Matrix Factorization - Epoch 17/30, Avg Gradient Norm: 741.6332, Noise Scale: 2.1527, RMSE: 1.8491, MAE: 1.4524, V Norm: 7.8646\n",
      "Matrix Factorization - Epoch 18/30, Avg Gradient Norm: 736.7207, Noise Scale: 2.0806, RMSE: 1.8484, MAE: 1.4517, V Norm: 7.8520\n",
      "Matrix Factorization - Epoch 19/30, Avg Gradient Norm: 731.6978, Noise Scale: 1.9998, RMSE: 1.8476, MAE: 1.4510, V Norm: 7.8398\n",
      "Matrix Factorization - Epoch 20/30, Avg Gradient Norm: 726.4765, Noise Scale: 1.9315, RMSE: 1.8468, MAE: 1.4501, V Norm: 7.8272\n",
      "Matrix Factorization - Epoch 21/30, Avg Gradient Norm: 720.9127, Noise Scale: 1.8589, RMSE: 1.8459, MAE: 1.4493, V Norm: 7.8152\n",
      "Matrix Factorization - Epoch 22/30, Avg Gradient Norm: 715.4054, Noise Scale: 1.7948, RMSE: 1.8448, MAE: 1.4482, V Norm: 7.8028\n",
      "Matrix Factorization - Epoch 23/30, Avg Gradient Norm: 709.7515, Noise Scale: 1.7318, RMSE: 1.8437, MAE: 1.4473, V Norm: 7.7905\n",
      "Matrix Factorization - Epoch 24/30, Avg Gradient Norm: 703.9594, Noise Scale: 1.6750, RMSE: 1.8426, MAE: 1.4463, V Norm: 7.7785\n",
      "Matrix Factorization - Epoch 25/30, Avg Gradient Norm: 697.8645, Noise Scale: 1.6123, RMSE: 1.8412, MAE: 1.4450, V Norm: 7.7661\n",
      "Matrix Factorization - Epoch 26/30, Avg Gradient Norm: 691.6539, Noise Scale: 1.5638, RMSE: 1.8408, MAE: 1.4448, V Norm: 7.7539\n",
      "Matrix Factorization - Epoch 27/30, Avg Gradient Norm: 685.3426, Noise Scale: 1.5024, RMSE: 1.8403, MAE: 1.4443, V Norm: 7.7419\n",
      "Matrix Factorization - Epoch 28/30, Avg Gradient Norm: 678.8744, Noise Scale: 1.4599, RMSE: 1.8395, MAE: 1.4438, V Norm: 7.7298\n",
      "Matrix Factorization - Epoch 29/30, Avg Gradient Norm: 672.1356, Noise Scale: 1.4089, RMSE: 1.8385, MAE: 1.4431, V Norm: 7.7181\n",
      "Matrix Factorization - Epoch 30/30, Avg Gradient Norm: 665.1884, Noise Scale: 1.3582, RMSE: 1.8376, MAE: 1.4423, V Norm: 7.7061\n",
      "Final Evaluation -> RMSE: 1.8376, MAE: 1.4423\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load MovieLens 100K data\n",
    "ratings_train = pd.read_csv('ml-100k/u1.base', sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "ratings_test = pd.read_csv('ml-100k/u1.test', sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "items = pd.read_csv('ml-100k/u.item', sep='|', encoding='latin-1', header=None)\n",
    "P = items.iloc[:, 5:24].values  # Item features (genres), shape (num_items, 19)\n",
    "\n",
    "# Get dimensions\n",
    "num_users = max(ratings_train['user_id'].max(), ratings_test['user_id'].max())\n",
    "num_items = max(ratings_train['item_id'].max(), ratings_test['item_id'].max())\n",
    "\n",
    "# Create rating matrix R with missing values as 0\n",
    "R = np.zeros((num_users, num_items))\n",
    "for row in ratings_train.itertuples():\n",
    "    R[row.user_id - 1, row.item_id - 1] = row.rating\n",
    "\n",
    "# Create mask for observed ratings in training set\n",
    "mask_train = np.zeros((num_users, num_items), dtype=bool)\n",
    "for row in ratings_train.itertuples():\n",
    "    mask_train[row.user_id - 1, row.item_id - 1] = True\n",
    "\n",
    "# Define Denoising User Autoencoder with deeper architecture\n",
    "class DenoisingUserAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout_rate=0.2):\n",
    "        super(DenoisingUserAutoencoder, self).__init__()\n",
    "        self.encoder1 = nn.Linear(input_dim, 512)\n",
    "        self.encoder2 = nn.Linear(512, hidden_dim)\n",
    "        self.decoder1 = nn.Linear(hidden_dim, 512)\n",
    "        self.decoder2 = nn.Linear(512, input_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_noisy = self.dropout(x)\n",
    "        h = F.relu(self.encoder1(x_noisy))\n",
    "        z = F.relu(self.encoder2(h))\n",
    "        h = F.relu(self.decoder1(z))\n",
    "        output = self.decoder2(h)\n",
    "        output = 1 + 4 * torch.sigmoid(output)  # Scale to [1, 5]\n",
    "        return output\n",
    "\n",
    "# Define Denoising Item Autoencoder with deeper architecture\n",
    "class DenoisingItemAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim_user_ratings, input_dim_item_features, hidden_dim, dropout_rate=0.2):\n",
    "        super(DenoisingItemAutoencoder, self).__init__()\n",
    "        self.encoder1 = nn.Linear(input_dim_user_ratings + input_dim_item_features, 512)\n",
    "        self.encoder2 = nn.Linear(512, hidden_dim)\n",
    "        self.decoder1 = nn.Linear(hidden_dim, 512)\n",
    "        self.decoder2 = nn.Linear(512, input_dim_user_ratings)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x_ratings, x_features):\n",
    "        x_ratings_noisy = self.dropout(x_ratings)\n",
    "        x = torch.cat([x_ratings_noisy, x_features], dim=1)\n",
    "        h = F.relu(self.encoder1(x))\n",
    "        z = F.relu(self.encoder2(h))\n",
    "        h = F.relu(self.decoder1(z))\n",
    "        output = self.decoder2(h)\n",
    "        output = 1 + 4 * torch.sigmoid(output)  # Scale to [1, 5]\n",
    "        return output\n",
    "\n",
    "# Define datasets\n",
    "class UserDataset(Dataset):\n",
    "    def __init__(self, R, mask):\n",
    "        self.R = R\n",
    "        self.mask = mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.R)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.R[idx], dtype=torch.float32), torch.tensor(self.mask[idx], dtype=torch.bool)\n",
    "\n",
    "class ItemDataset(Dataset):\n",
    "    def __init__(self, R, P, mask):\n",
    "        self.R = R.T  # (num_items, num_users)\n",
    "        self.P = P  # (num_items, num_features)\n",
    "        self.mask = mask.T  # (num_items, num_users)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.R)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.R[idx], dtype=torch.float32), torch.tensor(self.P[idx], dtype=torch.float32), torch.tensor(self.mask[idx], dtype=torch.bool)\n",
    "\n",
    "# Training function for denoising autoencoders\n",
    "def train_autoencoder(model, dataloader, num_epochs, learning_rate, model_name):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        for data in dataloader:\n",
    "            if len(data) == 2:\n",
    "                x, m = data\n",
    "                x = x.to(device)\n",
    "                m = m.to(device)\n",
    "                output = model(x)\n",
    "                loss = F.mse_loss(output[m], x[m], reduction='sum') / m.sum()\n",
    "            else:\n",
    "                x_ratings, x_features, m = data\n",
    "                x_ratings = x_ratings.to(device)\n",
    "                x_features = x_features.to(device)\n",
    "                m = m.to(device)\n",
    "                output = model(x_ratings, x_features)\n",
    "                loss = F.mse_loss(output[m], x_ratings[m], reduction='sum') / m.sum()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"{model_name} - Epoch {epoch+1}/{num_epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyperparameters\n",
    "d = 200\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100  # Increased epochs\n",
    "learning_rate_mf = 0.0005  # Lowered learning rate\n",
    "num_epochs_mf = 30\n",
    "C = 1.0\n",
    "epsilon = 5.0\n",
    "lambda_v = 0.2  # Increased regularization\n",
    "weight_decay_mf = 0.02  # Increased weight decay\n",
    "dropout_rate = 0.2  # Reduced dropout rate\n",
    "\n",
    "# Train denoising user autoencoder\n",
    "model_user = DenoisingUserAutoencoder(input_dim=num_items, hidden_dim=d, dropout_rate=dropout_rate).to(device)\n",
    "dataset_user = UserDataset(R=R, mask=mask_train)\n",
    "dataloader_user = DataLoader(dataset_user, batch_size=64, shuffle=True)\n",
    "train_autoencoder(model_user, dataloader_user, num_epochs, learning_rate, model_name=\"DenoisingUserAE\")\n",
    "\n",
    "# Train denoising item autoencoder\n",
    "model_item = DenoisingItemAutoencoder(input_dim_user_ratings=num_users, input_dim_item_features=19, hidden_dim=d, dropout_rate=dropout_rate).to(device)\n",
    "dataset_item = ItemDataset(R=R, P=P, mask=mask_train)\n",
    "dataloader_item = DataLoader(dataset_item, batch_size=64, shuffle=True)\n",
    "train_autoencoder(model_item, dataloader_item, num_epochs, learning_rate, model_name=\"DenoisingItemAE\")\n",
    "\n",
    "# Extract latent factors\n",
    "with torch.no_grad():\n",
    "    R_tensor = torch.tensor(R, dtype=torch.float32).to(device)\n",
    "    U = model_user.encoder2(F.relu(model_user.encoder1(R_tensor))).cpu().numpy()  # User latent factors\n",
    "    item_inputs = np.concatenate([R.T, P], axis=1)\n",
    "    item_inputs_tensor = torch.tensor(item_inputs, dtype=torch.float32).to(device)\n",
    "    h = F.relu(model_item.encoder1(item_inputs_tensor))\n",
    "    V = model_item.encoder2(h).cpu().numpy()  # Initial item latent factors\n",
    "\n",
    "# Adaptive noise injection function\n",
    "def adaptive_noise_scale(epoch, total_epochs, base_scale, gradient_norm, max_norm=1000.0, min_scale_factor=0.2):\n",
    "    decay_factor = 1.0 / (1.0 + 2 * epoch / total_epochs)\n",
    "    norm_factor = min(gradient_norm / max_norm, 1.0) if gradient_norm > 0 else 1.0\n",
    "    scale = base_scale * decay_factor * norm_factor\n",
    "    return max(scale, base_scale * min_scale_factor)\n",
    "\n",
    "# Evaluate function for test set\n",
    "def evaluate(U, V, ratings_test):\n",
    "    test_pred = []\n",
    "    test_true = []\n",
    "    for row in ratings_test.itertuples():\n",
    "        i = row.user_id - 1\n",
    "        j = row.item_id - 1\n",
    "        pred = np.dot(U[i], V[j])\n",
    "        pred = np.clip(pred, 1, 5)\n",
    "        test_pred.append(pred)\n",
    "        test_true.append(row.rating)\n",
    "    rmse = np.sqrt(mean_squared_error(test_true, test_pred))\n",
    "    mae = mean_absolute_error(test_true, test_pred)\n",
    "    return rmse, mae\n",
    "\n",
    "# Initial evaluation\n",
    "initial_rmse, initial_mae = evaluate(U, V, ratings_test)\n",
    "print(f\"Initial Evaluation -> RMSE: {initial_rmse:.4f}, MAE: {initial_mae:.4f}\")\n",
    "\n",
    "# Train V with differentially private SGD and adaptive noise\n",
    "base_noise_scale = C / (epsilon / num_epochs_mf)  # Should be 0.066\n",
    "noise_scales = []\n",
    "gradient_norms = []\n",
    "rmse_values = [initial_rmse]\n",
    "mae_values = [initial_mae]\n",
    "v_norms = [np.linalg.norm(V, axis=1).mean()]\n",
    "\n",
    "for epoch in range(num_epochs_mf):\n",
    "    shuffled_ratings_train = ratings_train.sample(frac=1).reset_index(drop=True)\n",
    "    total_grad_norm = 0.0\n",
    "    num_updates = 0\n",
    "    epoch_noise_scales = []\n",
    "    \n",
    "    for row in shuffled_ratings_train.itertuples():\n",
    "        i = row.user_id - 1\n",
    "        j = row.item_id - 1\n",
    "        r = row.rating\n",
    "        pred = np.dot(U[i], V[j])\n",
    "        if mask_train[i, j]:\n",
    "            e = r - pred\n",
    "        else:\n",
    "            e = 0\n",
    "        g_j = -2 * e * U[i] + lambda_v * V[j]  # Gradient\n",
    "        norm_g_j = np.linalg.norm(g_j)\n",
    "        # Normalize gradient to prevent large norms\n",
    "        if norm_g_j > 0:\n",
    "            g_j = g_j / norm_g_j * min(norm_g_j, 1000.0)  # Cap gradient norm at 1000\n",
    "            norm_g_j = min(norm_g_j, 1000.0)\n",
    "        total_grad_norm += norm_g_j\n",
    "        num_updates += 1\n",
    "        gradient_norms.append(norm_g_j)\n",
    "        if norm_g_j > C:\n",
    "            g_j = g_j * (C / norm_g_j)  # Clip gradient\n",
    "        avg_grad_norm = total_grad_norm / num_updates if num_updates > 0 else 1.0\n",
    "        noise_scale = adaptive_noise_scale(epoch, num_epochs_mf, base_noise_scale, avg_grad_norm, max_norm=1000.0)\n",
    "        epoch_noise_scales.append(noise_scale)\n",
    "        noise = np.random.laplace(0, noise_scale, size=d)  # Add adaptive Laplace noise\n",
    "        g_j_noisy = g_j + noise\n",
    "        # Update V with weight decay\n",
    "        V[j] = V[j] * (1 - learning_rate_mf * weight_decay_mf) - learning_rate_mf * g_j_noisy\n",
    "    \n",
    "    noise_scales.append(np.mean(epoch_noise_scales))\n",
    "    rmse, mae = evaluate(U, V, ratings_test)\n",
    "    rmse_values.append(rmse)\n",
    "    mae_values.append(mae)\n",
    "    v_norms.append(np.linalg.norm(V, axis=1).mean())\n",
    "    print(f\"Matrix Factorization - Epoch {epoch+1}/{num_epochs_mf}, Avg Gradient Norm: {avg_grad_norm:.4f}, Noise Scale: {noise_scales[-1]:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}, V Norm: {v_norms[-1]:.4f}\")\n",
    "\n",
    "# Final evaluation\n",
    "final_rmse, final_mae = evaluate(U, V, ratings_test)\n",
    "print(f\"Final Evaluation -> RMSE: {final_rmse:.4f}, MAE: {final_mae:.4f}\")\n",
    "\n",
    "# Visualizations\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plot 1: Noise Scale Over Epochs\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.plot(range(1, num_epochs_mf + 1), noise_scales, marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Noise Scale')\n",
    "plt.title('Adaptive Noise Scale Over Epochs')\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot 2: RMSE Over Epochs\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.plot(range(num_epochs_mf + 1), rmse_values, marker='o', label='RMSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE Over Epochs')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Plot 3: MAE Over Epochs\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.plot(range(num_epochs_mf + 1), mae_values, marker='o', label='MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.title('MAE Over Epochs')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Plot 4: Gradient Norm Distribution\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.hist(gradient_norms, bins=50, density=True, alpha=0.7)\n",
    "plt.xlabel('Gradient Norm')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Gradient Norm Distribution')\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot 5: V Norm Over Epochs\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.plot(range(num_epochs_mf + 1), v_norms, marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average V Norm')\n",
    "plt.title('V Norm Over Epochs')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('dp_dae_metrics_fixed_final.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Final RMSE values from the first and second code\n",
    "final_rmse_first = 1.8791\n",
    "final_rmse_second = 1.8376\n",
    "\n",
    "# Labels and values\n",
    "labels = ['Original', 'Improved']\n",
    "values = [final_rmse_first, final_rmse_second]\n",
    "\n",
    "# Plot the bar graph\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(labels, values, color=['blue', 'orange'])\n",
    "\n",
    "# Add labels and title\n",
    "plt.ylabel('Final RMSE')\n",
    "plt.title('Comparison of Final RMSE Between Original and Improved Code')\n",
    "plt.ylim(1.8, 1.9)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:47: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:47: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/var/folders/nq/h1zy5t_10sj8vqx0zy16z_g40000gn/T/ipykernel_41904/1927877437.py:47: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  df = pd.read_csv(file_path, sep=\"\\s+\", names=[\"user\", \"item\", \"rating\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running training split experiments for filmtrust...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1830: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "/var/folders/nq/h1zy5t_10sj8vqx0zy16z_g40000gn/T/ipykernel_41904/1927877437.py:47: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  df = pd.read_csv(file_path, sep=\"\\s+\", names=[\"user\", \"item\", \"rating\"])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Per sample gradient is not initialized. Not updated in backward pass?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 502\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;66;03m# Run everything\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 502\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 472\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRunning training split experiments for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 472\u001b[0m     results, train_ratios \u001b[38;5;241m=\u001b[39m \u001b[43mrun_training_split_experiments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;66;03m# Create plots\u001b[39;00m\n\u001b[1;32m    474\u001b[0m     plot_training_split_results(results, train_ratios, dataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 321\u001b[0m, in \u001b[0;36mrun_training_split_experiments\u001b[0;34m(dataset_name, hidden_size)\u001b[0m\n\u001b[1;32m    319\u001b[0m model \u001b[38;5;241m=\u001b[39m model_fn()\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDP-DAE\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 321\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dpdae\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     model \u001b[38;5;241m=\u001b[39m train_hrsa(model, train_matrix, train_mask)\n",
      "Cell \u001b[0;32mIn[6], line 171\u001b[0m, in \u001b[0;36mtrain_dpdae\u001b[0;34m(model, train_matrix, mask, epsilon, epochs, lr, reg)\u001b[0m\n\u001b[1;32m    169\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(output[mask[:batch\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)]], batch[mask[:batch\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)]])\n\u001b[1;32m    170\u001b[0m         loss\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# Compute gradients\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m         \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Update model\u001b[39;00m\n\u001b[1;32m    172\u001b[0m         total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/opacus/optimizers/optimizer.py:554\u001b[0m, in \u001b[0;36mDPOptimizer.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[1;32m    553\u001b[0m         closure()\n\u001b[0;32m--> 554\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moriginal_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/opacus/optimizers/optimizer.py:537\u001b[0m, in \u001b[0;36mDPOptimizer.pre_step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;124;03mPerform actions specific to ``DPOptimizer`` before calling\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;124;03munderlying  ``optimizer.step()``\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;124;03m        returns the loss. Optional for most optimizers.\u001b[39;00m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;66;03m# The corner case when the optimizer has no trainable parameters.\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;66;03m# Essentially the DPOptimizer act as a normal optimizer\u001b[39;00m\n\u001b[0;32m--> 537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad_samples\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad_samples) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_and_accumulate()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/opacus/optimizers/optimizer.py:343\u001b[0m, in \u001b[0;36mDPOptimizer.grad_samples\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    341\u001b[0m ret \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams:\n\u001b[0;32m--> 343\u001b[0m     ret\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_flat_grad_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/opacus/optimizers/optimizer.py:280\u001b[0m, in \u001b[0;36mDPOptimizer._get_flat_grad_sample\u001b[0;34m(self, p)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer sample gradient not found. Are you using GradSampleModule?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m     )\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad_sample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer sample gradient is not initialized. Not updated in backward pass?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(p\u001b[38;5;241m.\u001b[39mgrad_sample, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    284\u001b[0m     ret \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mgrad_sample\n",
      "\u001b[0;31mValueError\u001b[0m: Per sample gradient is not initialized. Not updated in backward pass?"
     ]
    }
   ],
   "source": [
    "# Import libraries needed for the code\n",
    "import torch  # For building and training the DP-DAE model\n",
    "import torch.nn as nn  # For neural network layers\n",
    "import torch.optim as optim  # For optimization (training)\n",
    "from opacus import PrivacyEngine  # For differential privacy\n",
    "import pandas as pd  # For loading datasets (like ratings.dat)\n",
    "import numpy as np  # For math and arrays\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error  # For RMSE and MAE\n",
    "from sklearn.decomposition import TruncatedSVD  # For SVD model\n",
    "from scipy.sparse import csr_matrix  # For sparse matrices\n",
    "import matplotlib.pyplot as plt  # For plotting graphs\n",
    "import seaborn as sns  # For nicer plots\n",
    "import os  # For file paths\n",
    "from pathlib import Path  # For handling folders\n",
    "\n",
    "# Make results consistent by setting a random seed\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Use GPU if available (Colab provides a free GPU, faster than CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Dataset Paths ---\n",
    "# The code expects datasets in these Colab locations:\n",
    "# - Movielens-1M: /content/ml-1m/ratings.dat\n",
    "#   Format: user::item::rating::timestamp (e.g., 1::1::5::978300760)\n",
    "# - Movielens-10M: /content/ml-10m/ratings.dat\n",
    "#   Same format as Movielens-1M\n",
    "# - FilmTrust: /content/filmtrust/ratings.txt\n",
    "#   Format: user item rating (space-separated, e.g., 1 1 3.5)\n",
    "# You uploaded these to /content/ in Step 1\n",
    "# If FilmTrust is missing, use datasets = [\"ml-1m\", \"ml-10m\"] in main()\n",
    "\n",
    "def load_dataset(dataset_name):\n",
    "    \"\"\"\n",
    "    Load a dataset (FilmTrust, Movielens-1M, or Movielens-10M) into a matrix.\n",
    "    Returns: ratings matrix (users x items), number of users, number of items.\n",
    "    \"\"\"\n",
    "    # Set the folder where datasets are stored (Colab's root directory)\n",
    "    data_dir = \"content/\"  # Changed for Colab (was \"./data/\" on laptop)\n",
    "    \n",
    "    # Load the right file based on dataset name\n",
    "    if dataset_name == \"filmtrust\":\n",
    "        # FilmTrust: expects ratings.txt with space-separated user item rating\n",
    "        file_path = os.path.join(data_dir, \"filmtrust/ratings.txt\")\n",
    "        # Read the file using pandas (like a spreadsheet)\n",
    "        df = pd.read_csv(file_path, sep=\"\\s+\", names=[\"user\", \"item\", \"rating\"])\n",
    "    elif dataset_name == \"ml-1m\":\n",
    "        # Movielens-1M: expects ratings.dat with :: separator\n",
    "        file_path = os.path.join(data_dir, \"ml-1m/ratings.dat\")\n",
    "        df = pd.read_csv(file_path, sep=\"::\", names=[\"user\", \"item\", \"rating\", \"timestamp\"], engine=\"python\")\n",
    "    elif dataset_name == \"ml-10m\":\n",
    "        # Movielens-10M: same format as ml-1m\n",
    "        file_path = os.path.join(data_dir, \"ml-10m/ratings.dat\")\n",
    "        df = pd.read_csv(file_path, sep=\"::\", names=[\"user\", \"item\", \"rating\", \"timestamp\"], engine=\"python\")\n",
    "    else:\n",
    "        raise ValueError(\"Unknown dataset: \" + dataset_name)\n",
    "\n",
    "    # Get unique users and items (like rows and columns)\n",
    "    users = df[\"user\"].unique()\n",
    "    items = df[\"item\"].unique()\n",
    "    # Create a dictionary to map user IDs to row numbers (0, 1, 2, ...)\n",
    "    user2idx = {u: i for i, u in enumerate(users)}\n",
    "    # Same for items\n",
    "    item2idx = {i: j for j, i in enumerate(items)}\n",
    "    \n",
    "    # Create a matrix (users x items) filled with zeros\n",
    "    n_users, n_items = len(users), len(items)\n",
    "    ratings_matrix = np.zeros((n_users, n_items))\n",
    "    # Fill the matrix with ratings\n",
    "    for _, row in df.iterrows():\n",
    "        u, i, r = row[\"user\"], row[\"item\"], row[\"rating\"]\n",
    "        ratings_matrix[user2idx[u], item2idx[i]] = r\n",
    "    \n",
    "    return ratings_matrix, n_users, n_items\n",
    "\n",
    "def train_test_split(ratings_matrix, train_ratio):\n",
    "    \"\"\"\n",
    "    Split ratings into training (e.g., 70%) and test sets.\n",
    "    Returns: train matrix, test matrix, train mask, test mask.\n",
    "    \"\"\"\n",
    "    n_users, n_items = ratings_matrix.shape\n",
    "    # Create masks (True/False) to mark which ratings are in train/test\n",
    "    train_mask = np.zeros_like(ratings_matrix, dtype=bool)\n",
    "    test_mask = np.zeros_like(ratings_matrix, dtype=bool)\n",
    "    \n",
    "    # For each user, split their ratings randomly\n",
    "    for u in range(n_users):\n",
    "        # Find items this user rated (non-zero ratings)\n",
    "        rated_items = np.where(ratings_matrix[u] > 0)[0]\n",
    "        if len(rated_items) == 0:\n",
    "            continue  # Skip users with no ratings\n",
    "        # Shuffle the items randomly\n",
    "        np.random.shuffle(rated_items)\n",
    "        # Take train_ratio (e.g., 70%) for training\n",
    "        train_size = int(len(rated_items) * train_ratio)\n",
    "        # Mark training items as True\n",
    "        train_mask[u, rated_items[:train_size]] = True\n",
    "        # Mark test items as True\n",
    "        test_mask[u, rated_items[train_size:]] = True\n",
    "    \n",
    "    # Create train/test matrices (only keep ratings where mask is True)\n",
    "    train_matrix = ratings_matrix * train_mask\n",
    "    test_matrix = ratings_matrix * test_mask\n",
    "    return train_matrix, test_matrix, train_mask, test_mask\n",
    "\n",
    "# --- DP-DAE Model ---\n",
    "class DPDAE(nn.Module):\n",
    "    \"\"\"\n",
    "    DP-DAE model: combines dual semi-autoencoder and matrix factorization.\n",
    "    Takes ratings as input, predicts ratings as output.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_items, hidden_size):\n",
    "        super(DPDAE, self).__init__()\n",
    "        self.n_items = n_items\n",
    "        # Encoder: turns ratings into a smaller hidden layer (like summarizing)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(n_items, hidden_size),  # Input: n_items, Output: hidden_size\n",
    "            nn.ReLU()  # Activation function (makes it non-linear)\n",
    "        )\n",
    "        # Decoder: turns hidden layer back into ratings\n",
    "        self.decoder = nn.Linear(hidden_size, n_items)\n",
    "        # Matrix Factorization: embeddings for users and items\n",
    "        self.user_emb = nn.Embedding(n_items, hidden_size)\n",
    "        self.item_emb = nn.Embedding(n_items, hidden_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Autoencoder path: encode then decode ratings\n",
    "        encoded = self.encoder(x)\n",
    "        ae_output = self.decoder(encoded)\n",
    "        # Matrix Factorization path: use embeddings\n",
    "        user_vec = self.user_emb.weight\n",
    "        item_vec = self.item_emb.weight\n",
    "        mf_output = torch.matmul(encoded, item_vec.t())\n",
    "        # Combine both paths (equal weight)\n",
    "        return 0.5 * ae_output + 0.5 * mf_output\n",
    "\n",
    "def train_dpdae(model, train_matrix, mask, epsilon, epochs=50, lr=0.005, reg=0.02):\n",
    "    \"\"\"\n",
    "    Train DP-DAE with differential privacy (DPSGD).\n",
    "    Epsilon controls privacy (lower = more private, more noise).\n",
    "    \"\"\"\n",
    "    # Set up optimizer (like a tool to update the model)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=reg)\n",
    "    # Loss function: measures prediction error\n",
    "    criterion = nn.MSELoss(reduction=\"sum\")\n",
    "    \n",
    "    # Add differential privacy using Opacus\n",
    "    privacy_engine = PrivacyEngine()\n",
    "    model, optimizer, train_loader = privacy_engine.make_private(\n",
    "        module=model,\n",
    "        optimizer=optimizer,\n",
    "        data_loader=torch.utils.data.DataLoader(\n",
    "            torch.FloatTensor(train_matrix).to(device), batch_size=32, shuffle=True\n",
    "        ),\n",
    "        noise_multiplier=1.0,  # Controls noise (adjusted for epsilon)\n",
    "        max_grad_norm=1.0,  # Clips gradients for stability\n",
    "    )\n",
    "    \n",
    "    model.train()\n",
    "    # Train for multiple rounds (epochs)\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)  # Move data to GPU/CPU\n",
    "            optimizer.zero_grad()  # Clear old gradients\n",
    "            output = model(batch)  # Predict ratings\n",
    "            # Calculate error only for rated items\n",
    "            loss = criterion(output[mask[:batch.size(0)]], batch[mask[:batch.size(0)]])\n",
    "            loss.backward()  # Compute gradients\n",
    "            optimizer.step()  # Update model\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, test_matrix, test_mask):\n",
    "    \"\"\"\n",
    "    Test the model on test data, return RMSE and MAE.\n",
    "    RMSE: average error (bigger errors hurt more).\n",
    "    MAE: average absolute error.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(torch.FloatTensor(test_matrix).to(device))\n",
    "        pred = pred.cpu().numpy()\n",
    "        true = test_matrix[test_mask]\n",
    "        pred = pred[test_mask]\n",
    "        rmse = np.sqrt(mean_squared_error(true, pred))\n",
    "        mae = mean_absolute_error(true, pred)\n",
    "    return rmse, mae\n",
    "\n",
    "# --- Comparison Models ---\n",
    "class HRSA(nn.Module):\n",
    "    \"\"\"\n",
    "    HRSA: simplified autoencoder (no privacy, like DP-DAEs autoencoder part).\n",
    "    \"\"\"\n",
    "    def __init__(self, n_items, hidden_size):\n",
    "        super(HRSA, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(n_items, hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Linear(hidden_size, n_items)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "def train_hrsa(model, train_matrix, mask, epochs=50, lr=0.005, reg=0.02):\n",
    "    \"\"\"Train HRSA without privacy.\"\"\"\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=reg)\n",
    "    criterion = nn.MSELoss(reduction=\"sum\")\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        torch.FloatTensor(train_matrix).to(device), batch_size=32, shuffle=True\n",
    "    )\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch)\n",
    "            loss = criterion(output[mask[:batch.size(0)]], batch[mask[:batch.size(0)]])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "class SVDModel:\n",
    "    \"\"\"SVD: matrix factorization using scikit-learn.\"\"\"\n",
    "    def __init__(self, n_factors=100):\n",
    "        self.svd = TruncatedSVD(n_components=n_factors)\n",
    "    \n",
    "    def fit(self, train_matrix):\n",
    "        self.svd.fit(csr_matrix(train_matrix))\n",
    "        self.user_factors = self.svd.transform(csr_matrix(train_matrix))\n",
    "        self.item_factors = self.svd.components_.T\n",
    "    \n",
    "    def predict(self, test_matrix):\n",
    "        return np.dot(self.user_factors, self.item_factors.T)\n",
    "\n",
    "class DPMF:\n",
    "    \"\"\"DP-MF: matrix factorization with differential privacy (simplified).\"\"\"\n",
    "    def __init__(self, n_factors=100, epsilon=1.0):\n",
    "        self.n_factors = n_factors\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def fit(self, train_matrix):\n",
    "        n_users, n_items = train_matrix.shape\n",
    "        # Initialize random factors\n",
    "        self.user_factors = np.random.normal(0, 1, (n_users, self.n_factors))\n",
    "        self.item_factors = np.random.normal(0, 1, (n_items, self.n_factors))\n",
    "        # Add DP noise\n",
    "        noise_scale = np.sqrt(2 * np.log(1.25 / 0.01)) / self.epsilon\n",
    "        self.user_factors += np.random.normal(0, noise_scale, self.user_factors.shape)\n",
    "        self.item_factors += np.random.normal(0, noise_scale, self.item_factors.shape)\n",
    "    \n",
    "    def predict(self, test_matrix):\n",
    "        return np.dot(self.user_factors, self.item_factors.T)\n",
    "\n",
    "class DPCF:\n",
    "    \"\"\"DP-CF: collaborative filtering with DP (simplified).\"\"\"\n",
    "    def __init__(self, epsilon=1.0):\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def fit(self, train_matrix):\n",
    "        # Compute item similarity with DP noise\n",
    "        self.sim_matrix = np.dot(train_matrix.T, train_matrix)\n",
    "        noise_scale = np.sqrt(2 * np.log(1.25 / 0.01)) / self.epsilon\n",
    "        self.sim_matrix += np.random.normal(0, noise_scale, self.sim_matrix.shape)\n",
    "    \n",
    "    def predict(self, test_matrix):\n",
    "        return np.dot(test_matrix, self.sim_matrix)\n",
    "\n",
    "class ItemAgrec:\n",
    "    \"\"\"Item-Agrec: item similarity (simplified, no attributes).\"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, train_matrix):\n",
    "        # Cosine similarity on ratings\n",
    "        norm = np.sqrt((train_matrix ** 2).sum(axis=0))\n",
    "        norm[norm == 0] = 1\n",
    "        self.sim_matrix = np.dot(train_matrix.T, train_matrix) / norm[:, None] / norm[None, :]\n",
    "    \n",
    "    def predict(self, test_matrix):\n",
    "        return np.dot(test_matrix, self.sim_matrix)\n",
    "\n",
    "# --- Experiment Functions ---\n",
    "def run_training_split_experiments(dataset_name, hidden_size=250):\n",
    "    \"\"\"\n",
    "    Run experiments for training splits (70%, 80%, 90%).\n",
    "    Matches Tables 49 and Figures 56 (RMSE/MAE vs. training ratio).\n",
    "    \"\"\"\n",
    "    # Load the dataset\n",
    "    ratings_matrix, n_users, n_items = load_dataset(dataset_name)\n",
    "    train_ratios = [0.7, 0.8, 0.9]\n",
    "    # Define all models to compare\n",
    "    models = {\n",
    "        \"DP-DAE\": lambda: DPDAE(n_items, hidden_size).to(device),\n",
    "        \"HRSA\": lambda: HRSA(n_items, hidden_size).to(device),\n",
    "        \"SVD\": lambda: SVDModel(),\n",
    "        \"DP-MF\": lambda: DPMF(epsilon=1.0),\n",
    "        \"DP-CF\": lambda: DPCF(epsilon=1.0),\n",
    "        \"Item-Agrec\": lambda: ItemAgrec()\n",
    "    }\n",
    "    \n",
    "    # Store results (RMSE and MAE for each model)\n",
    "    results = {model: {\"RMSE\": [], \"MAE\": []} for model in models}\n",
    "    \n",
    "    # Test each training split\n",
    "    for ratio in train_ratios:\n",
    "        # Split data\n",
    "        train_matrix, test_matrix, train_mask, test_mask = train_test_split(ratings_matrix, ratio)\n",
    "        \n",
    "        # Train and test each model\n",
    "        for model_name, model_fn in models.items():\n",
    "            if model_name in [\"DP-DAE\", \"HRSA\"]:\n",
    "                # Neural network models\n",
    "                model = model_fn()\n",
    "                if model_name == \"DP-DAE\":\n",
    "                    model = train_dpdae(model, train_matrix, train_mask, epsilon=1.0)\n",
    "                else:\n",
    "                    model = train_hrsa(model, train_matrix, train_mask)\n",
    "                rmse, mae = evaluate_model(model, test_matrix, test_mask)\n",
    "            else:\n",
    "                # Non-neural models\n",
    "                model = model_fn()\n",
    "                model.fit(train_matrix)\n",
    "                pred = model.predict(test_matrix)\n",
    "                true = test_matrix[test_mask]\n",
    "                pred = pred[test_mask]\n",
    "                rmse = np.sqrt(mean_squared_error(true, pred))\n",
    "                mae = mean_absolute_error(true, pred)\n",
    "            \n",
    "            results[model_name][\"RMSE\"].append(rmse)\n",
    "            results[model_name][\"MAE\"].append(mae)\n",
    "    \n",
    "    return results, train_ratios\n",
    "\n",
    "def run_epsilon_experiments(dataset_name, hidden_size=250):\n",
    "    \"\"\"\n",
    "    Run experiments for different privacy budgets ( = 0.1, 1, 5, 10).\n",
    "    Matches Figures 89 (RMSE vs. ).\n",
    "    Shows high RMSE at =0.1 (limitation).\n",
    "    \"\"\"\n",
    "    ratings_matrix, n_users, n_items = load_dataset(dataset_name)\n",
    "    epsilons = [0.1, 1.0, 5.0, 10.0]\n",
    "    models = {\n",
    "        \"DP-DAE\": lambda: DPDAE(n_items, hidden_size).to(device),\n",
    "        \"SVD\": lambda: SVDModel(),\n",
    "        \"DP-MF\": lambda epsilon: DPMF(epsilon=epsilon),\n",
    "        \"DP-NMF\": lambda epsilon: DPMF(epsilon=epsilon),  # Simplified as DP-MF\n",
    "        \"DPSGD\": lambda: DPDAE(n_items, hidden_size).to(device)  # DP-DAE with higher noise\n",
    "    }\n",
    "    \n",
    "    results = {model: [] for model in models}\n",
    "    # Use 80% training split (like the paper)\n",
    "    train_matrix, test_matrix, train_mask, test_mask = train_test_split(ratings_matrix, 0.8)\n",
    "    \n",
    "    for eps in epsilons:\n",
    "        for model_name, model_fn in models.items():\n",
    "            if model_name in [\"DP-DAE\", \"DPSGD\"]:\n",
    "                model = model_fn()\n",
    "                model = train_dpdae(model, train_matrix, train_mask, epsilon=eps)\n",
    "                rmse, _ = evaluate_model(model, test_matrix, test_mask)\n",
    "            elif model_name in [\"DP-MF\", \"DP-NMF\"]:\n",
    "                model = model_fn(epsilon=eps)\n",
    "                model.fit(train_matrix)\n",
    "                pred = model.predict(test_matrix)\n",
    "                rmse = np.sqrt(mean_squared_error(test_matrix[test_mask], pred[test_mask]))\n",
    "            else:\n",
    "                model = model_fn()\n",
    "                model.fit(train_matrix)\n",
    "                pred = model.predict(test_matrix)\n",
    "                rmse = np.sqrt(mean_squared_error(test_matrix[test_mask], pred[test_mask]))\n",
    "            \n",
    "            results[model_name].append(rmse)\n",
    "    \n",
    "    return results, epsilons\n",
    "\n",
    "def run_hidden_layer_experiments(dataset_name, train_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Run experiments for hidden layer sizes (50, 150, 250, 350, 450).\n",
    "    Matches Figures 1011 (RMSE vs. hidden layer size).\n",
    "    \"\"\"\n",
    "    ratings_matrix, n_users, n_items = load_dataset(dataset_name)\n",
    "    hidden_sizes = [50, 150, 250, 350, 450]\n",
    "    models = {\n",
    "        \"DP-DAE\": lambda hs: DPDAE(n_items, hs).to(device),\n",
    "        \"AE\": lambda hs: HRSA(n_items, hs).to(device),  # Non-DP autoencoder\n",
    "        \"DP-AE\": lambda hs: DPDAE(n_items, hs).to(device)\n",
    "    }\n",
    "    \n",
    "    results = {model: [] for model in models}\n",
    "    train_matrix, test_matrix, train_mask, test_mask = train_test_split(ratings_matrix, train_ratio)\n",
    "    \n",
    "    for hs in hidden_sizes:\n",
    "        for model_name, model_fn in models.items():\n",
    "            model = model_fn(hs)\n",
    "            if model_name in [\"DP-DAE\", \"DP-AE\"]:\n",
    "                model = train_dpdae(model, train_matrix, train_mask, epsilon=1.0)\n",
    "            else:\n",
    "                model = train_hrsa(model, train_matrix, train_mask)\n",
    "            rmse, _ = evaluate_model(model, test_matrix, test_mask)\n",
    "            results[model_name].append(rmse)\n",
    "    \n",
    "    return results, hidden_sizes\n",
    "\n",
    "# --- Plotting Functions ---\n",
    "def plot_training_split_results(results, train_ratios, dataset_name, metric=\"RMSE\"):\n",
    "    \"\"\"\n",
    "    Create plots for Figures 56 (RMSE/MAE vs. training ratio).\n",
    "    Saves as PNG (e.g., ml-1m_rmse_training_split.png).\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for model_name, metrics in results.items():\n",
    "        plt.plot(train_ratios, metrics[metric], marker=\"o\", label=model_name)\n",
    "    plt.xlabel(\"Training Ratio\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.title(f\"{metric} vs. Training Ratio ({dataset_name})\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f\"{dataset_name}_{metric}_training_split.png\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_epsilon_results(results, epsilons, dataset_name):\n",
    "    \"\"\"\n",
    "    Create plots for Figures 89 (RMSE vs. ).\n",
    "    Shows high RMSE at =0.1 (limitation).\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for model_name, rmses in results.items():\n",
    "        plt.plot(epsilons, rmses, marker=\"o\", label=model_name)\n",
    "    plt.xlabel(\"Privacy Budget ()\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.title(f\"RMSE vs.  ({dataset_name})\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f\"{dataset_name}_rmse_epsilon.png\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_hidden_layer_results(results, hidden_sizes, dataset_name):\n",
    "    \"\"\"\n",
    "    Create plots for Figures 1011 (RMSE vs. hidden layer size).\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for model_name, rmses in results.items():\n",
    "        plt.plot(hidden_sizes, rmses, marker=\"o\", label=model_name)\n",
    "    plt.xlabel(\"Hidden Layer Size\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.title(f\"RMSE vs. Hidden Layer Size ({dataset_name})\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f\"{dataset_name}_rmse_hidden_layer.png\")\n",
    "    plt.close()\n",
    "\n",
    "# --- Main Function ---\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Run all experiments and create graphs/tables.\n",
    "    Change datasets list if FilmTrust is missing.\n",
    "    \"\"\"\n",
    "    # List of datasets to run\n",
    "    datasets = [\"filmtrust\", \"ml-1m\", \"ml-10m\"]  # Use this if you have FilmTrust\n",
    "    # If FilmTrust is missing, use this:\n",
    "    # For quick testing, use this:\n",
    "    # datasets = [\"ml-1m\"]\n",
    "    \n",
    "    # Training Split Experiments (Tables 49, Figures 56)\n",
    "    for dataset in datasets:\n",
    "        print(f\"\\nRunning training split experiments for {dataset}...\")\n",
    "        results, train_ratios = run_training_split_experiments(dataset)\n",
    "        # Create plots\n",
    "        plot_training_split_results(results, train_ratios, dataset, \"RMSE\")\n",
    "        plot_training_split_results(results, train_ratios, dataset, \"MAE\")\n",
    "        # Print results (like Tables 49)\n",
    "        print(f\"\\n{dataset} Training Split Results:\")\n",
    "        for model_name, metrics in results.items():\n",
    "            print(f\"{model_name} RMSE: {metrics['RMSE']}\")\n",
    "            print(f\"{model_name} MAE: {metrics['MAE']}\")\n",
    "    \n",
    "    # Epsilon Experiments (Figures 89)\n",
    "    for dataset in datasets[:2]:  # Skip ml-10m for speed\n",
    "        print(f\"\\nRunning epsilon experiments for {dataset}...\")\n",
    "        results, epsilons = run_epsilon_experiments(dataset)\n",
    "        plot_epsilon_results(results, epsilons, dataset)\n",
    "        print(f\"\\n{dataset} Epsilon Results:\")\n",
    "        for model_name, rmses in results.items():\n",
    "            print(f\"{model_name} RMSE: {rmses}\")\n",
    "    \n",
    "    # Hidden Layer Experiments (Figures 1011)\n",
    "    for dataset in datasets[:2]:  # Skip ml-10m for speed\n",
    "        print(f\"\\nRunning hidden layer experiments for {dataset}...\")\n",
    "        results, hidden_sizes = run_hidden_layer_experiments(dataset)\n",
    "        plot_hidden_layer_results(results, hidden_sizes, dataset)\n",
    "        print(f\"\\n{dataset} Hidden Layer Results:\")\n",
    "        for model_name, rmses in results.items():\n",
    "            print(f\"{model_name} RMSE: {rmses}\")\n",
    "\n",
    "# Run everything\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:39: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:39: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/var/folders/nq/h1zy5t_10sj8vqx0zy16z_g40000gn/T/ipykernel_41904/3618004481.py:39: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  df = pd.read_csv(file_path, sep=\"\\s+\", names=[\"user\", \"item\", \"rating\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running training split experiments for ml-1m...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1830: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Per sample gradient is not initialized. Not updated in backward pass?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 451\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;66;03m# Run everything\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 451\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[21], line 425\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRunning training split experiments for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 425\u001b[0m     results, train_ratios \u001b[38;5;241m=\u001b[39m \u001b[43mrun_training_split_experiments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m     plot_training_split_results(results, train_ratios, dataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    427\u001b[0m     plot_training_split_results(results, train_ratios, dataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAE\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[21], line 283\u001b[0m, in \u001b[0;36mrun_training_split_experiments\u001b[0;34m(dataset_name, hidden_size)\u001b[0m\n\u001b[1;32m    281\u001b[0m model \u001b[38;5;241m=\u001b[39m model_fn()\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDP-DAE\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 283\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dpdae\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    285\u001b[0m     model \u001b[38;5;241m=\u001b[39m train_hrsa(model, train_matrix, train_mask)\n",
      "Cell \u001b[0;32mIn[21], line 146\u001b[0m, in \u001b[0;36mtrain_dpdae\u001b[0;34m(model, train_matrix, mask, epsilon, epochs, lr, reg)\u001b[0m\n\u001b[1;32m    144\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(output[mask[:batch\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)]], batch[mask[:batch\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)]])\n\u001b[1;32m    145\u001b[0m         loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m--> 146\u001b[0m         \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m         total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/opacus/optimizers/optimizer.py:554\u001b[0m, in \u001b[0;36mDPOptimizer.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[1;32m    553\u001b[0m         closure()\n\u001b[0;32m--> 554\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moriginal_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/opacus/optimizers/optimizer.py:537\u001b[0m, in \u001b[0;36mDPOptimizer.pre_step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;124;03mPerform actions specific to ``DPOptimizer`` before calling\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;124;03munderlying  ``optimizer.step()``\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;124;03m        returns the loss. Optional for most optimizers.\u001b[39;00m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;66;03m# The corner case when the optimizer has no trainable parameters.\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;66;03m# Essentially the DPOptimizer act as a normal optimizer\u001b[39;00m\n\u001b[0;32m--> 537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad_samples\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad_samples) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_and_accumulate()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/opacus/optimizers/optimizer.py:343\u001b[0m, in \u001b[0;36mDPOptimizer.grad_samples\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    341\u001b[0m ret \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams:\n\u001b[0;32m--> 343\u001b[0m     ret\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_flat_grad_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/opacus/optimizers/optimizer.py:280\u001b[0m, in \u001b[0;36mDPOptimizer._get_flat_grad_sample\u001b[0;34m(self, p)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer sample gradient not found. Are you using GradSampleModule?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m     )\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad_sample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer sample gradient is not initialized. Not updated in backward pass?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(p\u001b[38;5;241m.\u001b[39mgrad_sample, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    284\u001b[0m     ret \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mgrad_sample\n",
      "\u001b[0;31mValueError\u001b[0m: Per sample gradient is not initialized. Not updated in backward pass?"
     ]
    }
   ],
   "source": [
    "# Import libraries needed for the code\n",
    "import torch  # For building and training the DP-DAE model\n",
    "import torch.nn as nn  # For neural network layers\n",
    "import torch.optim as optim  # For optimization (training)\n",
    "from opacus import PrivacyEngine  # For differential privacy\n",
    "import pandas as pd  # For loading datasets (like ratings.dat)\n",
    "import numpy as np  # For math and arrays\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error  # For RMSE and MAE\n",
    "from sklearn.decomposition import TruncatedSVD  # For SVD model\n",
    "from scipy.sparse import csr_matrix  # For sparse matrices\n",
    "import matplotlib.pyplot as plt  # For plotting graphs\n",
    "import seaborn as sns  # For nicer plots\n",
    "import os  # For file paths\n",
    "from pathlib import Path  # For handling folders\n",
    "\n",
    "# Make results consistent by setting a random seed\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Use GPU if available (Colab provides a free GPU, faster than CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Dataset Paths ---\n",
    "# Expects datasets in:\n",
    "# - Movielens-1M: /content/ml-1m/ratings.dat (user::item::rating::timestamp)\n",
    "# - Movielens-10M: /content/ml-10m/ratings.dat (same format)\n",
    "# - FilmTrust: /content/filmtrust/ratings.txt (user item rating, space-separated)\n",
    "# Using ml-1m and ml-10m; change datasets list if FilmTrust available\n",
    "\n",
    "def load_dataset(dataset_name):\n",
    "    \"\"\"\n",
    "    Load a dataset into a matrix.\n",
    "    Returns: ratings matrix (users x items), number of users, number of items.\n",
    "    \"\"\"\n",
    "    data_dir = \"content/\"  # Colab's root directory\n",
    "    \n",
    "    if dataset_name == \"filmtrust\":\n",
    "        file_path = os.path.join(data_dir, \"filmtrust/ratings.txt\")\n",
    "        df = pd.read_csv(file_path, sep=\"\\s+\", names=[\"user\", \"item\", \"rating\"])\n",
    "    elif dataset_name == \"ml-1m\":\n",
    "        file_path = os.path.join(data_dir, \"ml-1m/ratings.dat\")\n",
    "        df = pd.read_csv(file_path, sep=\"::\", names=[\"user\", \"item\", \"rating\", \"timestamp\"], engine=\"python\")\n",
    "    elif dataset_name == \"ml-10m\":\n",
    "        file_path = os.path.join(data_dir, \"ml-10m/ratings.dat\")\n",
    "        df = pd.read_csv(file_path, sep=\"::\", names=[\"user\", \"item\", \"rating\", \"timestamp\"], engine=\"python\")\n",
    "    else:\n",
    "        raise ValueError(\"Unknown dataset: \" + dataset_name)\n",
    "\n",
    "    users = df[\"user\"].unique()\n",
    "    items = df[\"item\"].unique()\n",
    "    user2idx = {u: i for i, u in enumerate(users)}\n",
    "    item2idx = {i: j for j, i in enumerate(items)}\n",
    "    \n",
    "    n_users, n_items = len(users), len(items)\n",
    "    ratings_matrix = np.zeros((n_users, n_items))\n",
    "    for _, row in df.iterrows():\n",
    "        u, i, r = row[\"user\"], row[\"item\"], row[\"rating\"]\n",
    "        ratings_matrix[user2idx[u], item2idx[i]] = r\n",
    "    \n",
    "    return ratings_matrix, n_users, n_items\n",
    "\n",
    "def train_test_split(ratings_matrix, train_ratio):\n",
    "    \"\"\"\n",
    "    Split ratings into training and test sets.\n",
    "    Returns: train matrix, test matrix, train mask, test mask.\n",
    "    \"\"\"\n",
    "    n_users, n_items = ratings_matrix.shape\n",
    "    train_mask = np.zeros_like(ratings_matrix, dtype=bool)\n",
    "    test_mask = np.zeros_like(ratings_matrix, dtype=bool)\n",
    "    \n",
    "    for u in range(n_users):\n",
    "        rated_items = np.where(ratings_matrix[u] > 0)[0]\n",
    "        if len(rated_items) == 0:\n",
    "            continue\n",
    "        np.random.shuffle(rated_items)\n",
    "        train_size = int(len(rated_items) * train_ratio)\n",
    "        train_mask[u, rated_items[:train_size]] = True\n",
    "        test_mask[u, rated_items[train_size:]] = True\n",
    "    \n",
    "    train_matrix = ratings_matrix * train_mask\n",
    "    test_matrix = ratings_matrix * test_mask\n",
    "    return train_matrix, test_matrix, train_mask, test_mask\n",
    "\n",
    "# --- DP-DAE Model ---\n",
    "class DPDAE(nn.Module):\n",
    "    \"\"\"\n",
    "    DP-DAE model: combines dual semi-autoencoder and matrix factorization.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_items, hidden_size):\n",
    "        super(DPDAE, self).__init__()\n",
    "        self.n_items = n_items\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(n_items, hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Linear(hidden_size, n_items)\n",
    "        self.user_emb = nn.Embedding(n_items, hidden_size)\n",
    "        self.item_emb = nn.Embedding(n_items, hidden_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        ae_output = self.decoder(encoded)\n",
    "        user_vec = self.user_emb.weight\n",
    "        item_vec = self.item_emb.weight\n",
    "        mf_output = torch.matmul(encoded, item_vec.t())\n",
    "        return 0.5 * ae_output + 0.5 * mf_output\n",
    "\n",
    "def train_dpdae(model, train_matrix, mask, epsilon, epochs=50, lr=0.005, reg=0.02):\n",
    "    \"\"\"\n",
    "    Train DP-DAE with differential privacy (DPSGD).\n",
    "    Fixed for opacus compatibility with per-sample gradients.\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Set up optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=reg)  # Switch to Adam for stability\n",
    "    criterion = nn.MSELoss(reduction=\"sum\")\n",
    "    \n",
    "    # Create data loader\n",
    "    train_dataset = torch.FloatTensor(train_matrix).to(device)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    # Add differential privacy\n",
    "    privacy_engine = PrivacyEngine()\n",
    "    model, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n",
    "        module=model,\n",
    "        optimizer=optimizer,\n",
    "        data_loader=train_loader,\n",
    "        target_epsilon=epsilon,\n",
    "        target_delta=1e-5,\n",
    "        epochs=epochs,\n",
    "        max_grad_norm=1.0,\n",
    "        poisson_sampling=False,\n",
    "        grad_sample_mode=\"functorch\"  # Use functorch for nn.Embedding\n",
    "    )\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch)\n",
    "            loss = criterion(output[mask[:batch.size(0)]], batch[mask[:batch.size(0)]])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, test_matrix, test_mask):\n",
    "    \"\"\"\n",
    "    Test the model, return RMSE and MAE.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(torch.FloatTensor(test_matrix).to(device))\n",
    "        pred = pred.cpu().numpy()\n",
    "        true = test_matrix[test_mask]\n",
    "        pred = pred[test_mask]\n",
    "        rmse = np.sqrt(mean_squared_error(true, pred))\n",
    "        mae = mean_absolute_error(true, pred)\n",
    "    return rmse, mae\n",
    "\n",
    "# --- Comparison Models ---\n",
    "class HRSA(nn.Module):\n",
    "    \"\"\"\n",
    "    HRSA: simplified autoencoder (no privacy).\n",
    "    \"\"\"\n",
    "    def __init__(self, n_items, hidden_size):\n",
    "        super(HRSA, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(n_items, hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Linear(hidden_size, n_items)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "def train_hrsa(model, train_matrix, mask, epochs=50, lr=0.005, reg=0.02):\n",
    "    \"\"\"Train HRSA without privacy.\"\"\"\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=reg)\n",
    "    criterion = nn.MSELoss(reduction=\"sum\")\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        torch.FloatTensor(train_matrix).to(device), batch_size=32, shuffle=True\n",
    "    )\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch)\n",
    "            loss = criterion(output[mask[:batch.size(0)]], batch[mask[:batch.size(0)]])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "class SVDModel:\n",
    "    \"\"\"SVD: matrix factorization.\"\"\"\n",
    "    def __init__(self, n_factors=100):\n",
    "        self.svd = TruncatedSVD(n_components=n_factors)\n",
    "    \n",
    "    def fit(self, train_matrix):\n",
    "        self.svd.fit(csr_matrix(train_matrix))\n",
    "        self.user_factors = self.svd.transform(csr_matrix(train_matrix))\n",
    "        self.item_factors = self.svd.components_.T\n",
    "    \n",
    "    def predict(self, test_matrix):\n",
    "        return np.dot(self.user_factors, self.item_factors.T)\n",
    "\n",
    "class DPMF:\n",
    "    \"\"\"DP-MF: matrix factorization with DP.\"\"\"\n",
    "    def __init__(self, n_factors=100, epsilon=1.0):\n",
    "        self.n_factors = n_factors\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def fit(self, train_matrix):\n",
    "        n_users, n_items = train_matrix.shape\n",
    "        self.user_factors = np.random.normal(0, 1, (n_users, self.n_factors))\n",
    "        self.item_factors = np.random.normal(0, 1, (n_items, self.n_factors))\n",
    "        noise_scale = np.sqrt(2 * np.log(1.25 / 0.01)) / self.epsilon\n",
    "        self.user_factors += np.random.normal(0, noise_scale, self.user_factors.shape)\n",
    "        self.item_factors += np.random.normal(0, noise_scale, self.item_factors.shape)\n",
    "    \n",
    "    def predict(self, test_matrix):\n",
    "        return np.dot(self.user_factors, self.item_factors.T)\n",
    "\n",
    "class DPCF:\n",
    "    \"\"\"DP-CF: collaborative filtering with DP.\"\"\"\n",
    "    def __init__(self, epsilon=1.0):\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def fit(self, train_matrix):\n",
    "        self.sim_matrix = np.dot(train_matrix.T, train_matrix)\n",
    "        noise_scale = np.sqrt(2 * np.log(1.25 / 0.01)) / self.epsilon\n",
    "        self.sim_matrix += np.random.normal(0, noise_scale, self.sim_matrix.shape)\n",
    "    \n",
    "    def predict(self, test_matrix):\n",
    "        return np.dot(test_matrix, self.sim_matrix)\n",
    "\n",
    "class ItemAgrec:\n",
    "    \"\"\"Item-Agrec: item similarity.\"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, train_matrix):\n",
    "        norm = np.sqrt((train_matrix ** 2).sum(axis=0))\n",
    "        norm[norm == 0] = 1\n",
    "        self.sim_matrix = np.dot(train_matrix.T, train_matrix) / norm[:, None] / norm[None, :]\n",
    "    \n",
    "    def predict(self, test_matrix):\n",
    "        return np.dot(test_matrix, self.sim_matrix)\n",
    "\n",
    "# --- Experiment Functions ---\n",
    "def run_training_split_experiments(dataset_name, hidden_size=250):\n",
    "    \"\"\"\n",
    "    Run experiments for training splits (70%, 80%, 90%).\n",
    "    Matches Tables 49, Figures 56.\n",
    "    \"\"\"\n",
    "    ratings_matrix, n_users, n_items = load_dataset(dataset_name)\n",
    "    train_ratios = [0.7, 0.8, 0.9]\n",
    "    models = {\n",
    "        \"DP-DAE\": lambda: DPDAE(n_items, hidden_size).to(device),\n",
    "        \"HRSA\": lambda: HRSA(n_items, hidden_size).to(device),\n",
    "        \"SVD\": lambda: SVDModel(),\n",
    "        \"DP-MF\": lambda: DPMF(epsilon=1.0),\n",
    "        \"DP-CF\": lambda: DPCF(epsilon=1.0),\n",
    "        \"Item-Agrec\": lambda: ItemAgrec()\n",
    "    }\n",
    "    \n",
    "    results = {model: {\"RMSE\": [], \"MAE\": []} for model in models}\n",
    "    \n",
    "    for ratio in train_ratios:\n",
    "        train_matrix, test_matrix, train_mask, test_mask = train_test_split(ratings_matrix, ratio)\n",
    "        \n",
    "        for model_name, model_fn in models.items():\n",
    "            if model_name in [\"DP-DAE\", \"HRSA\"]:\n",
    "                model = model_fn()\n",
    "                if model_name == \"DP-DAE\":\n",
    "                    model = train_dpdae(model, train_matrix, train_mask, epsilon=1.0)\n",
    "                else:\n",
    "                    model = train_hrsa(model, train_matrix, train_mask)\n",
    "                rmse, mae = evaluate_model(model, test_matrix, test_mask)\n",
    "            else:\n",
    "                model = model_fn()\n",
    "                model.fit(train_matrix)\n",
    "                pred = model.predict(test_matrix)\n",
    "                true = test_matrix[test_mask]\n",
    "                pred = pred[test_mask]\n",
    "                rmse = np.sqrt(mean_squared_error(true, pred))\n",
    "                mae = mean_absolute_error(true, pred)\n",
    "            \n",
    "            results[model_name][\"RMSE\"].append(rmse)\n",
    "            results[model_name][\"MAE\"].append(mae)\n",
    "    \n",
    "    return results, train_ratios\n",
    "\n",
    "def run_epsilon_experiments(dataset_name, hidden_size=250):\n",
    "    \"\"\"\n",
    "    Run experiments for privacy budgets ( = 0.1, 1, 5, 10).\n",
    "    Matches Figures 89 (high RMSE at =0.1).\n",
    "    \"\"\"\n",
    "    ratings_matrix, n_users, n_items = load_dataset(dataset_name)\n",
    "    epsilons = [0.1, 1.0, 5.0, 10.0]\n",
    "    models = {\n",
    "        \"DP-DAE\": lambda: DPDAE(n_items, hidden_size).to(device),\n",
    "        \"SVD\": lambda: SVDModel(),\n",
    "        \"DP-MF\": lambda epsilon: DPMF(epsilon=epsilon),\n",
    "        \"DP-NMF\": lambda epsilon: DPMF(epsilon=epsilon),\n",
    "        \"DPSGD\": lambda: DPDAE(n_items, hidden_size).to(device)\n",
    "    }\n",
    "    \n",
    "    results = {model: [] for model in models}\n",
    "    train_matrix, test_matrix, train_mask, test_mask = train_test_split(ratings_matrix, 0.8)\n",
    "    \n",
    "    for eps in epsilons:\n",
    "        for model_name, model_fn in models.items():\n",
    "            if model_name in [\"DP-DAE\", \"DPSGD\"]:\n",
    "                model = model_fn()\n",
    "                model = train_dpdae(model, train_matrix, train_mask, epsilon=eps)\n",
    "                rmse, _ = evaluate_model(model, test_matrix, test_mask)\n",
    "            elif model_name in [\"DP-MF\", \"DP-NMF\"]:\n",
    "                model = model_fn(epsilon=eps)\n",
    "                model.fit(train_matrix)\n",
    "                pred = model.predict(test_matrix)\n",
    "                rmse = np.sqrt(mean_squared_error(test_matrix[test_mask], pred[test_mask]))\n",
    "            else:\n",
    "                model = model_fn()\n",
    "                model.fit(train_matrix)\n",
    "                pred = model.predict(test_matrix)\n",
    "                rmse = np.sqrt(mean_squared_error(test_matrix[test_mask], pred[test_mask]))\n",
    "            \n",
    "            results[model_name].append(rmse)\n",
    "    \n",
    "    return results, epsilons\n",
    "\n",
    "def run_hidden_layer_experiments(dataset_name, train_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Run experiments for hidden layer sizes (50, 150, 250, 350, 450).\n",
    "    Matches Figures 1011.\n",
    "    \"\"\"\n",
    "    ratings_matrix, n_users, n_items = load_dataset(dataset_name)\n",
    "    hidden_sizes = [50, 150, 250, 350, 450]\n",
    "    models = {\n",
    "        \"DP-DAE\": lambda hs: DPDAE(n_items, hs).to(device),\n",
    "        \"AE\": lambda hs: HRSA(n_items, hs).to(device),\n",
    "        \"DP-AE\": lambda hs: DPDAE(n_items, hs).to(device)\n",
    "    }\n",
    "    \n",
    "    results = {model: [] for model in models}\n",
    "    train_matrix, test_matrix, train_mask, test_mask = train_test_split(ratings_matrix, train_ratio)\n",
    "    \n",
    "    for hs in hidden_sizes:\n",
    "        for model_name, model_fn in models.items():\n",
    "            model = model_fn(hs)\n",
    "            if model_name in [\"DP-DAE\", \"DP-AE\"]:\n",
    "                model = train_dpdae(model, train_matrix, train_mask, epsilon=1.0)\n",
    "            else:\n",
    "                model = train_hrsa(model, train_matrix, train_mask)\n",
    "            rmse, _ = evaluate_model(model, test_matrix, test_mask)\n",
    "            results[model_name].append(rmse)\n",
    "    \n",
    "    return results, hidden_sizes\n",
    "\n",
    "# --- Plotting Functions ---\n",
    "def plot_training_split_results(results, train_ratios, dataset_name, metric=\"RMSE\"):\n",
    "    \"\"\"\n",
    "    Create plots for Figures 56.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for model_name, metrics in results.items():\n",
    "        plt.plot(train_ratios, metrics[metric], marker=\"o\", label=model_name)\n",
    "    plt.xlabel(\"Training Ratio\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.title(f\"{metric} vs. Training Ratio ({dataset_name})\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f\"{dataset_name}_{metric}_training_split.png\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_epsilon_results(results, epsilons, dataset_name):\n",
    "    \"\"\"\n",
    "    Create plots for Figures 89.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for model_name, rmses in results.items():\n",
    "        plt.plot(epsilons, rmses, marker=\"o\", label=model_name)\n",
    "    plt.xlabel(\"Privacy Budget ()\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.title(f\"RMSE vs.  ({dataset_name})\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f\"{dataset_name}_rmse_epsilon.png\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_hidden_layer_results(results, hidden_sizes, dataset_name):\n",
    "    \"\"\"\n",
    "    Create plots for Figures 1011.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for model_name, rmses in results.items():\n",
    "        plt.plot(hidden_sizes, rmses, marker=\"o\", label=model_name)\n",
    "    plt.xlabel(\"Hidden Layer Size\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.title(f\"RMSE vs. Hidden Layer Size ({dataset_name})\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f\"{dataset_name}_rmse_hidden_layer.png\")\n",
    "    plt.close()\n",
    "\n",
    "# --- Main Function ---\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Run all experiments and create graphs/tables.\n",
    "    Using ml-1m and ml-10m; change if FilmTrust available.\n",
    "    \"\"\"\n",
    "    datasets = [\"ml-1m\", \"ml-10m\"]  # Use [\"filmtrust\", \"ml-1m\", \"ml-10m\"] if FilmTrust available\n",
    "    # For quick testing: datasets = [\"ml-1m\"]\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        print(f\"\\nRunning training split experiments for {dataset}...\")\n",
    "        results, train_ratios = run_training_split_experiments(dataset)\n",
    "        plot_training_split_results(results, train_ratios, dataset, \"RMSE\")\n",
    "        plot_training_split_results(results, train_ratios, dataset, \"MAE\")\n",
    "        print(f\"\\n{dataset} Training Split Results:\")\n",
    "        for model_name, metrics in results.items():\n",
    "            print(f\"{model_name} RMSE: {metrics['RMSE']}\")\n",
    "            print(f\"{model_name} MAE: {metrics['MAE']}\")\n",
    "    \n",
    "    for dataset in datasets[:2]:\n",
    "        print(f\"\\nRunning epsilon experiments for {dataset}...\")\n",
    "        results, epsilons = run_epsilon_experiments(dataset)\n",
    "        plot_epsilon_results(results, epsilons, dataset)\n",
    "        print(f\"\\n{dataset} Epsilon Results:\")\n",
    "        for model_name, rmses in results.items():\n",
    "            print(f\"{model_name} RMSE: {rmses}\")\n",
    "    \n",
    "    for dataset in datasets[:2]:\n",
    "        print(f\"\\nRunning hidden layer experiments for {dataset}...\")\n",
    "        results, hidden_sizes = run_hidden_layer_experiments(dataset)\n",
    "        plot_hidden_layer_results(results, hidden_sizes, dataset)\n",
    "        print(f\"\\n{dataset} Hidden Layer Results:\")\n",
    "        for model_name, rmses in results.items():\n",
    "            print(f\"{model_name} RMSE: {rmses}\")\n",
    "\n",
    "# Run everything\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Index put requires the source and destination dtypes match, got Float for the destination and Long for the source.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 83\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (u, i, r, _) \u001b[38;5;129;01min\u001b[39;00m interactions:\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# 5.1 Build per-example inputs\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     Ru \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, n_items, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m---> 83\u001b[0m     \u001b[43mRu\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43mu\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[1;32m     84\u001b[0m         df_train[df_train\u001b[38;5;241m.\u001b[39muser\u001b[38;5;241m==\u001b[39mu]\u001b[38;5;241m.\u001b[39mrating\u001b[38;5;241m.\u001b[39mvalues, device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m     85\u001b[0m     )\n\u001b[1;32m     86\u001b[0m     Ri \u001b[38;5;241m=\u001b[39m Ru\u001b[38;5;241m.\u001b[39mt()  \u001b[38;5;66;03m# treats Ru row as item ratings\u001b[39;00m\n\u001b[1;32m     87\u001b[0m     Pi \u001b[38;5;241m=\u001b[39m P[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)    \u001b[38;5;66;03m# [1n_feat]\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Index put requires the source and destination dtypes match, got Float for the destination and Long for the source."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 1. Load data (u1.base / u1.test)\n",
    "def load_ml100k(path, split='u1'):\n",
    "    df_train = pd.read_csv(f'{path}/{split}.base', sep='\\t', header=None,\n",
    "                           names=['user','item','rating','ts'])\n",
    "    df_test  = pd.read_csv(f'{path}/{split}.test', sep='\\t', header=None,\n",
    "                           names=['user','item','rating','ts'])\n",
    "    items    = pd.read_csv(f'{path}/u.item', sep='|', header=None,\n",
    "                           encoding='latin-1', usecols=range(5,24))\n",
    "    P = torch.FloatTensor(items.values)  # genres: [num_items19]\n",
    "\n",
    "    n_users = int(max(df_train.user.max(), df_test.user.max()))\n",
    "    n_items = int(max(df_train.item.max(), df_test.item.max()))\n",
    "\n",
    "    return df_train, df_test, P, n_users, n_items\n",
    "\n",
    "df_train, df_test, P, n_users, n_items = load_ml100k('ml-100k', 'u1')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "P = P.to(device)\n",
    "\n",
    "# 2. Model (joint user + item semi-autoencoder)\n",
    "class JointDPDAE(nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_feat, L=50):\n",
    "        super().__init__()\n",
    "        # user branch\n",
    "        self.u_enc = nn.Sequential(\n",
    "            nn.Linear(n_items, 200), nn.Sigmoid(),\n",
    "            nn.Linear(200, L),      nn.Sigmoid()\n",
    "        )\n",
    "        self.u_dec = nn.Sequential(\n",
    "            nn.Linear(L, 200),      nn.Sigmoid(),\n",
    "            nn.Linear(200, n_items)\n",
    "        )\n",
    "        # item branch (with metadata)\n",
    "        self.i_enc = nn.Sequential(\n",
    "            nn.Linear(n_users + n_feat, 200), nn.Sigmoid(),\n",
    "            nn.Linear(200, L),               nn.Sigmoid()\n",
    "        )\n",
    "        self.i_dec = nn.Sequential(\n",
    "            nn.Linear(L, 200),      nn.Sigmoid(),\n",
    "            nn.Linear(200, n_users)\n",
    "        )\n",
    "\n",
    "    def forward(self, Ru, Ri, Pi):\n",
    "        # Ru: [1n_items], Ri: [1n_users], Pi: [1n_feat]\n",
    "        u_lat = self.u_enc(Ru)\n",
    "        u_rec = self.u_dec(u_lat)\n",
    "        x     = torch.cat([Ri, Pi], dim=1)\n",
    "        i_lat = self.i_enc(x)\n",
    "        i_rec = self.i_dec(i_lat)\n",
    "        return u_rec, u_lat, i_rec, i_lat\n",
    "\n",
    "model = JointDPDAE(n_users, n_items, P.size(1), L=50).to(device)\n",
    "\n",
    "# 3. Hyperparams & DP settings\n",
    "C               = 1.0        # grad-norm clip\n",
    "epsilon_per_upd = 0.1        # budget per single rating update\n",
    "epochs          = 20\n",
    "lam_mf          = 0.3        # MF loss weight\n",
    "lam_reg         = 1e-5       # L2 reg weight\n",
    "lr              = 1e-2\n",
    "\n",
    "optim_sgd = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# 4. Prepare interaction list for stochastic updates\n",
    "#    Each element: (u, i, r)\n",
    "interactions = list(df_train.itertuples(index=False, name=None))\n",
    "total_eps     = 0.0\n",
    "\n",
    "# 5. Training loop\n",
    "for epoch in range(1, epochs+1):\n",
    "    np.random.shuffle(interactions)\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for (u, i, r, _) in interactions:\n",
    "        # 5.1 Build per-example inputs\n",
    "        Ru = torch.zeros(1, n_items, device=device)\n",
    "        Ru[0, df_train[df_train.user==u].item.values -1] = torch.tensor(\n",
    "            df_train[df_train.user==u].rating.values, device=device\n",
    "        )\n",
    "        Ri = Ru.t()  # treats Ru row as item ratings\n",
    "        Pi = P[i-1].unsqueeze(0)    # [1n_feat]\n",
    "\n",
    "        # 5.2 Forward\n",
    "        optim_sgd.zero_grad()\n",
    "        u_rec, u_lat, i_rec, i_lat = model(Ru, Ri, Pi)\n",
    "\n",
    "        # 5.3 Compute losses (only observed entry (u,i) matters for this update)\n",
    "        #    plus MF and reg\n",
    "        rec_u = (u_rec[0, i-1] - r)**2            # user-AE reconstruction\n",
    "        rec_i = (i_rec[0, u-1] - r)**2            # item-AE reconstruction\n",
    "        pred  = (u_lat @ i_lat.t())[0,0]\n",
    "        mf    = (pred - r)**2                    # MF term\n",
    "        reg   = sum(p.pow(2).sum() for p in model.parameters())\n",
    "\n",
    "        loss = rec_u + rec_i + lam_mf*mf + lam_reg*reg\n",
    "        loss.backward()\n",
    "\n",
    "        # 5.4 DP-SGD gradient clipping + Laplace noise\n",
    "        for p in model.parameters():\n",
    "            if p.grad is None: continue\n",
    "            g = p.grad.data\n",
    "            norm = g.norm()\n",
    "            if norm > C:\n",
    "                g.mul_(C / norm)\n",
    "            # Laplace noise: scale = C/\n",
    "            scale = C / epsilon_per_upd\n",
    "            lap  = torch.distributions.Laplace(0, scale).sample(g.shape).to(device)\n",
    "            p.grad.data = g + lap\n",
    "\n",
    "        optim_sgd.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 5.5 Accumulate \n",
    "        total_eps += epsilon_per_upd\n",
    "\n",
    "    avg_loss = running_loss / len(interactions)\n",
    "    print(f'Epoch {epoch}/{epochs}  Avg Loss: {avg_loss:.4f}  _so_far: {total_eps:.1f}')\n",
    "\n",
    "# 6. Final evaluation on test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    se, cnt = 0.0, 0\n",
    "    for (u,i,r,_) in df_test.itertuples(index=False, name=None):\n",
    "        Ru = torch.zeros(1, n_items, device=device)\n",
    "        Ru[0, df_train[df_train.user==u].item.values -1] = torch.tensor(\n",
    "            df_train[df_train.user==u].rating.values, device=device\n",
    "        )\n",
    "        Ri = Ru.t()\n",
    "        Pi = P[i-1].unsqueeze(0)\n",
    "        _, u_lat, _, i_lat = model(Ru, Ri, Pi)\n",
    "        pred = (u_lat @ i_lat.t())[0,0].item()\n",
    "        pred = min(5, max(1, pred))\n",
    "        se  += (pred - r)**2\n",
    "        cnt += 1\n",
    "    rmse = np.sqrt(se / cnt)\n",
    "    print(f'\\nFinal Test RMSE: {rmse:.4f}  Total : {total_eps:.1f}')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
